# Milvus Standalone éƒ¨ç½²ä¸å¼€å‘æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°å¦‚ä½•åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­å¿«é€Ÿéƒ¨ç½²å’Œä½¿ç”¨ Milvus standalone æ¨¡å¼ï¼Œä¸º Agent æ™ºèƒ½å’¨è¯¢ç³»ç»Ÿæä¾›å‘é‡å­˜å‚¨æ”¯æŒã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿéƒ¨ç½²ï¼‰

### 1. ç¯å¢ƒè¦æ±‚

```bash
# ç³»ç»Ÿè¦æ±‚
- Docker >= 20.10
- Docker Compose >= 1.29
- Python >= 3.8
- å†…å­˜ >= 8GBï¼ˆæ¨è16GBï¼‰
- ç£ç›˜ç©ºé—´ >= 10GB
```

### 2. ä¸€é”®éƒ¨ç½²

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir ~/milvus-standalone && cd ~/milvus-standalone

# ä¸‹è½½å®˜æ–¹ standalone compose æ–‡ä»¶ï¼ˆæ¨èé”å®šç‰ˆæœ¬ï¼‰
wget https://github.com/milvus-io/milvus/releases/download/v2.3.3/milvus-standalone-docker-compose.yml -O docker-compose.yml

# å¯åŠ¨æœåŠ¡ï¼ˆåå°è¿è¡Œï¼‰
docker compose up -d

# éªŒè¯çŠ¶æ€
docker compose ps
```

### 3. ç«‹å³éªŒè¯

```bash
# æŸ¥çœ‹æ—¥å¿—ç¡®è®¤æ— é”™è¯¯
docker logs milvus-standalone --tail 50

# æµ‹è¯•ç«¯å£è¿é€šæ€§
curl -f http://localhost:9091/health

# é¢„æœŸè¾“å‡ºï¼š{"status":"ok"}
```

## ğŸ”§ å¼€å‘ç¯å¢ƒé…ç½®

### Python ç¯å¢ƒè®¾ç½®

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv milvus-env
source milvus-env/bin/activate  # Linux/Mac
# milvus-env\Scripts\activate     # Windows

# å®‰è£…ä¾èµ–
pip install pymilvus==2.3.3
pip install numpy==1.24.3
pip install pandas==2.0.3
```

### è¿æ¥æµ‹è¯•è„šæœ¬

åˆ›å»º `test_connection.py`:

```python
#!/usr/bin/env python3
"""Milvus è¿æ¥æµ‹è¯•è„šæœ¬"""

from pymilvus import connections, utility, Collection, FieldSchema, CollectionSchema, DataType
import sys

def test_basic_connection():
    """æµ‹è¯•åŸºç¡€è¿æ¥"""
    try:
        # è¿æ¥ Milvus
        connections.connect(
            alias="default",
            host="127.0.0.1",
            port="19530"
        )

        # è·å–æœåŠ¡å™¨ç‰ˆæœ¬
        version = utility.get_server_version()
        print(f"âœ… Milvus è¿æ¥æˆåŠŸï¼ç‰ˆæœ¬: {version}")

        # è·å–ç³»ç»Ÿä¿¡æ¯
        sys_info = utility.get_system_info()
        print(f"ğŸ“Š ç³»ç»Ÿä¿¡æ¯: {sys_info}")

        return True

    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return False

def test_collection_operations():
    """æµ‹è¯•é›†åˆæ“ä½œ"""
    try:
        # å®šä¹‰é›†åˆschema
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=768),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535)
        ]

        schema = CollectionSchema(fields, "æµ‹è¯•é›†åˆ")

        # åˆ›å»ºé›†åˆ
        collection_name = "test_collection"
        if utility.has_collection(collection_name):
            utility.drop_collection(collection_name)

        collection = Collection(name=collection_name, schema=schema)
        print(f"âœ… åˆ›å»ºé›†åˆæˆåŠŸ: {collection_name}")

        # æ’å…¥æµ‹è¯•æ•°æ®
        import numpy as np

        vectors = np.random.random((100, 768)).astype(np.float32).tolist()
        texts = [f"æµ‹è¯•æ–‡æœ¬_{i}" for i in range(100)]

        entities = [vectors, texts]
        collection.insert(entities)
        print(f"âœ… æ’å…¥æ•°æ®æˆåŠŸ: 100æ¡è®°å½•")

        # åˆ›å»ºç´¢å¼•
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 128}
        }
        collection.create_index("vector", index_params)
        print(f"âœ… åˆ›å»ºç´¢å¼•æˆåŠŸ")

        # åŠ è½½é›†åˆå¹¶æœç´¢
        collection.load()

        # æœç´¢æµ‹è¯•
        search_vectors = np.random.random((1, 768)).astype(np.float32).tolist()
        search_params = {"metric_type": "L2", "params": {"nprobe": 16}}

        results = collection.search(
            data=search_vectors,
            anns_field="vector",
            param=search_params,
            limit=5,
            output_fields=["text"]
        )

        print(f"âœ… å‘é‡æœç´¢æˆåŠŸï¼Œè¿”å› {len(results[0])} æ¡ç»“æœ")

        # æ¸…ç†
        collection.drop()
        print(f"âœ… æ¸…ç†å®Œæˆ")

        return True

    except Exception as e:
        print(f"âŒ é›†åˆæ“ä½œå¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Milvus Standalone è¿æ¥æµ‹è¯•å¼€å§‹...")

    # åŸºç¡€è¿æ¥æµ‹è¯•
    if not test_basic_connection():
        sys.exit(1)

    # é›†åˆæ“ä½œæµ‹è¯•
    if not test_collection_operations():
        sys.exit(1)

    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Milvus Standalone è¿è¡Œæ­£å¸¸")

    # å…³é—­è¿æ¥
    connections.disconnect("default")

if __name__ == "__main__":
    main()
```

è¿è¡Œæµ‹è¯•ï¼š
```bash
python test_connection.py
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

åˆ›å»º `benchmark_test.py`:

```python
#!/usr/bin/env python3
"""Milvus æ€§èƒ½åŸºå‡†æµ‹è¯•"""

import time
import numpy as np
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

class MilvusBenchmark:
    def __init__(self):
        self.collection_name = "benchmark_collection"
        self.dim = 768
        self.connect()
        self.setup_collection()

    def connect(self):
        """è¿æ¥Milvus"""
        connections.connect(
            alias="default",
            host="127.0.0.1",
            port="19530"
        )

    def setup_collection(self):
        """è®¾ç½®æµ‹è¯•é›†åˆ"""
        from pymilvus import utility

        # åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
        if utility.has_collection(self.collection_name):
            utility.drop_collection(self.collection_name)

        # å®šä¹‰Schema
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=self.dim),
            FieldSchema(name="timestamp", dtype=DataType.INT64)
        ]

        schema = CollectionSchema(fields, "åŸºå‡†æµ‹è¯•é›†åˆ")
        self.collection = Collection(name=self.collection_name, schema=schema)

    def test_insert_performance(self, num_entities=10000, batch_size=1000):
        """æµ‹è¯•æ’å…¥æ€§èƒ½"""
        print(f"\nğŸ“¥ æ’å…¥æ€§èƒ½æµ‹è¯•: {num_entities} æ¡è®°å½•, batch_size={batch_size}")

        total_time = 0
        for i in range(0, num_entities, batch_size):
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            vectors = np.random.random((batch_size, self.dim)).astype(np.float32).tolist()
            timestamps = [int(time.time()) + j for j in range(batch_size)]

            # æ’å…¥æ•°æ®
            start_time = time.time()
            entities = [vectors, timestamps]
            self.collection.insert(entities)
            insert_time = time.time() - start_time
            total_time += insert_time

            print(f"  Batch {i//batch_size + 1}: {batch_size} æ¡, è€—æ—¶ {insert_time:.3f}s, "
                  f"QPS: {batch_size/insert_time:.0f}")

        avg_qps = num_entities / total_time
        print(f"âœ… æ’å…¥å®Œæˆ: æ€»è€—æ—¶ {total_time:.3f}s, å¹³å‡ QPS: {avg_qps:.0f}")
        return avg_qps

    def test_search_performance(self, num_queries=1000, top_k=10):
        """æµ‹è¯•æœç´¢æ€§èƒ½"""
        print(f"\nğŸ” æœç´¢æ€§èƒ½æµ‹è¯•: {num_queries} æ¬¡æŸ¥è¯¢, top_k={top_k}")

        # åˆ›å»ºç´¢å¼•
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 128}
        }
        self.collection.create_index("vector", index_params)
        self.collection.load()

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vectors = np.random.random((num_queries, self.dim)).astype(np.float32).tolist()
        search_params = {"metric_type": "L2", "params": {"nprobe": 16}}

        # æ‰§è¡Œæœç´¢
        start_time = time.time()
        for i, query_vector in enumerate(query_vectors):
            results = self.collection.search(
                data=[query_vector],
                anns_field="vector",
                param=search_params,
                limit=top_k
            )

        total_time = time.time() - start_time
        avg_latency = (total_time / num_queries) * 1000  # ms
        avg_qps = num_queries / total_time

        print(f"âœ… æœç´¢å®Œæˆ: æ€»è€—æ—¶ {total_time:.3f}s")
        print(f"  å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"  å¹³å‡ QPS: {avg_qps:.0f}")

        return avg_latency, avg_qps

    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        from pymilvus import utility
        utility.drop_collection(self.collection_name)
        print("\nğŸ§¹ æµ‹è¯•æ•°æ®å·²æ¸…ç†")

def main():
    print("ğŸš€ Milvus Standalone æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)

    benchmark = MilvusBenchmark()

    try:
        # æ’å…¥æ€§èƒ½æµ‹è¯•
        insert_qps = benchmark.test_insert_performance(num_entities=10000, batch_size=1000)

        # æœç´¢æ€§èƒ½æµ‹è¯•
        search_latency, search_qps = benchmark.test_search_performance(num_queries=1000, top_k=10)

        print("\n" + "=" * 50)
        print("ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  æ’å…¥ QPS: {insert_qps:.0f}")
        print(f"  æœç´¢å»¶è¿Ÿ: {search_latency:.2f}ms")
        print(f"  æœç´¢ QPS: {search_qps:.0f}")

        # æ€§èƒ½åŸºå‡†åˆ¤æ–­
        if insert_qps > 5000 and search_latency < 50:
            print("\nâœ… æ€§èƒ½è¾¾æ ‡ï¼é€‚åˆç”Ÿäº§ç¯å¢ƒä½¿ç”¨")
        else:
            print("\nâš ï¸  æ€§èƒ½ä¸€èˆ¬ï¼Œå»ºè®®è°ƒä¼˜åå†ä½¿ç”¨")

    finally:
        benchmark.cleanup()
        connections.disconnect("default")

if __name__ == "__main__":
    main()
```

## ğŸ”§ å¸¸ç”¨ç®¡ç†æ“ä½œ

### æœåŠ¡ç®¡ç†è„šæœ¬

åˆ›å»º `milvus_manager.py`:

```python
#!/usr/bin/env python3
"""Milvus æœåŠ¡ç®¡ç†å·¥å…·"""

import subprocess
import time
import requests
import sys
from pathlib import Path

class MilvusManager:
    def __init__(self, compose_file="docker-compose.yml"):
        self.compose_file = Path(compose_file)
        self.milvus_port = 19530
        self.metrics_port = 9091

    def start(self):
        """å¯åŠ¨MilvusæœåŠ¡"""
        print("ğŸš€ æ­£åœ¨å¯åŠ¨ Milvus Standalone...")
        try:
            result = subprocess.run(
                ["docker", "compose", "up", "-d"],
                cwd=self.compose_file.parent,
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                print("âœ… Milvus å®¹å™¨å·²å¯åŠ¨")
                self.wait_for_healthy()
                return True
            else:
                print(f"âŒ å¯åŠ¨å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            print(f"âŒ å¯åŠ¨å¼‚å¸¸: {e}")
            return False

    def stop(self):
        """åœæ­¢MilvusæœåŠ¡"""
        print("ğŸ›‘ æ­£åœ¨åœæ­¢ Milvus Standalone...")
        try:
            result = subprocess.run(
                ["docker", "compose", "down"],
                cwd=self.compose_file.parent,
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                print("âœ… Milvus å®¹å™¨å·²åœæ­¢")
                return True
            else:
                print(f"âŒ åœæ­¢å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            print(f"âŒ åœæ­¢å¼‚å¸¸: {e}")
            return False

    def restart(self):
        """é‡å¯MilvusæœåŠ¡"""
        print("ğŸ”„ æ­£åœ¨é‡å¯ Milvus Standalone...")
        if self.stop():
            time.sleep(3)
            return self.start()
        return False

    def status(self):
        """æŸ¥çœ‹æœåŠ¡çŠ¶æ€"""
        try:
            # æ£€æŸ¥å®¹å™¨çŠ¶æ€
            result = subprocess.run(
                ["docker", "compose", "ps"],
                cwd=self.compose_file.parent,
                capture_output=True,
                text=True
            )

            print("ğŸ“Š å®¹å™¨çŠ¶æ€:")
            print(result.stdout)

            # æ£€æŸ¥å¥åº·çŠ¶æ€
            self.check_health()

        except Exception as e:
            print(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}")

    def check_health(self):
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            # æ£€æŸ¥metricsç«¯å£
            response = requests.get(f"http://localhost:{self.metrics_port}/health", timeout=5)
            if response.status_code == 200:
                print("âœ… Milvus æœåŠ¡å¥åº·")
                return True
            else:
                print(f"âš ï¸  æœåŠ¡çŠ¶æ€å¼‚å¸¸: {response.status_code}")
                return False

        except requests.exceptions.RequestException as e:
            print(f"âŒ æœåŠ¡è¿æ¥å¤±è´¥: {e}")
            return False

    def logs(self, tail=50):
        """æŸ¥çœ‹æœåŠ¡æ—¥å¿—"""
        try:
            result = subprocess.run(
                ["docker", "logs", "milvus-standalone", f"--tail={tail}"],
                capture_output=True,
                text=True
            )

            print(f"ğŸ“‹ æœ€è¿‘ {tail} è¡Œæ—¥å¿—:")
            print(result.stdout)

            if result.stderr:
                print("âš ï¸  é”™è¯¯æ—¥å¿—:")
                print(result.stderr)

        except Exception as e:
            print(f"âŒ è·å–æ—¥å¿—å¤±è´¥: {e}")

    def clean_data(self):
        """æ¸…ç†æ‰€æœ‰æ•°æ®ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
        print("âš ï¸  å³å°†æ¸…ç†æ‰€æœ‰Milvusæ•°æ®ï¼")
        confirm = input("ç¡®è®¤è¦ç»§ç»­å—? (yes/no): ")

        if confirm.lower() == "yes":
            print("ğŸ§¹ æ­£åœ¨æ¸…ç†æ•°æ®...")
            try:
                result = subprocess.run(
                    ["docker", "compose", "down", "-v"],
                    cwd=self.compose_file.parent,
                    capture_output=True,
                    text=True
                )

                if result.returncode == 0:
                    print("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
                    return True
                else:
                    print(f"âŒ æ¸…ç†å¤±è´¥: {result.stderr}")
                    return False

            except Exception as e:
                print(f"âŒ æ¸…ç†å¼‚å¸¸: {e}")
                return False
        else:
            print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
            return False

def main():
    """å‘½ä»¤è¡Œç•Œé¢"""
    import argparse

    parser = argparse.ArgumentParser(description="Milvus Standalone ç®¡ç†å·¥å…·")
    parser.add_argument("command", choices=["start", "stop", "restart", "status", "logs", "clean"],
                       help="ç®¡ç†å‘½ä»¤")
    parser.add_argument("--tail", type=int, default=50, help="æ—¥å¿—è¡Œæ•°")

    args = parser.parse_args()

    manager = MilvusManager()

    commands = {
        "start": manager.start,
        "stop": manager.stop,
        "restart": manager.restart,
        "status": manager.status,
        "logs": lambda: manager.logs(args.tail),
        "clean": manager.clean_data
    }

    if args.command in commands:
        success = commands[args.command]()
        sys.exit(0 if success else 1)
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {args.command}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## ğŸ“Š èµ„æºç›‘æ§

### èµ„æºä½¿ç”¨ç›‘æ§è„šæœ¬

åˆ›å»º `resource_monitor.py`:

```python
#!/usr/bin/env python3
"""Milvus èµ„æºç›‘æ§"""

import subprocess
import time
import json
from datetime import datetime

class ResourceMonitor:
    def __init__(self):
        self.container_name = "milvus-standalone"

    def get_container_stats(self):
        """è·å–å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            result = subprocess.run(
                ["docker", "stats", self.container_name, "--no-stream", "--format", "json"],
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                stats = json.loads(result.stdout)
                return {
                    "timestamp": datetime.now().isoformat(),
                    "cpu_percent": stats.get("CPUPerc", "0%").rstrip("%"),
                    "memory_usage": stats.get("MemUsage", "0B / 0B"),
                    "memory_percent": stats.get("MemPerc", "0%").rstrip("%"),
                    "network_io": stats.get("NetIO", "0B / 0B"),
                    "block_io": stats.get("BlockIO", "0B / 0B")
                }
            else:
                return None

        except Exception as e:
            print(f"è·å–å®¹å™¨çŠ¶æ€å¤±è´¥: {e}")
            return None

    def get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        try:
            # è·å–Dockerç³»ç»Ÿä¿¡æ¯
            result = subprocess.run(
                ["docker", "system", "df", "--format", "json"],
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                return None

        except Exception as e:
            print(f"è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {e}")
            return None

    def monitor_continuously(self, interval=5, duration=60):
        """æŒç»­ç›‘æ§èµ„æºä½¿ç”¨"""
        print(f"ğŸ” å¼€å§‹ç›‘æ§èµ„æºä½¿ç”¨ (é—´éš”: {interval}s, æŒç»­æ—¶é—´: {duration}s)")
        print("-" * 80)

        stats_history = []
        start_time = time.time()

        try:
            while time.time() - start_time < duration:
                stats = self.get_container_stats()
                if stats:
                    stats_history.append(stats)
                    self.print_stats(stats)

                time.sleep(interval)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç›‘æ§è¢«ä¸­æ–­")

        print("\n" + "=" * 80)
        print("ğŸ“Š ç›‘æ§æ€»ç»“:")
        self.print_summary(stats_history)

    def print_stats(self, stats):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        timestamp = datetime.fromisoformat(stats["timestamp"]).strftime("%H:%M:%S")
        print(f"[{timestamp}] CPU: {stats['cpu_percent']:>6}% | "
              f"å†…å­˜: {stats['memory_percent']:>6}% | "
              f"ç½‘ç»œ: {stats['network_io']}")

    def print_summary(self, stats_history):
        """æ‰“å°ç›‘æ§æ€»ç»“"""
        if not stats_history:
            print("âŒ æ²¡æœ‰æ”¶é›†åˆ°ç›‘æ§æ•°æ®")
            return

        cpu_values = [float(s["cpu_percent"]) for s in stats_history]
        memory_values = [float(s["memory_percent"]) for s in stats_history]

        avg_cpu = sum(cpu_values) / len(cpu_values)
        max_cpu = max(cpu_values)
        avg_memory = sum(memory_values) / len(memory_values)
        max_memory = max(memory_values)

        print(f"å¹³å‡ CPU ä½¿ç”¨ç‡: {avg_cpu:.1f}%")
        print(f"å³°å€¼ CPU ä½¿ç”¨ç‡: {max_cpu:.1f}%")
        print(f"å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%")
        print(f"å³°å€¼å†…å­˜ä½¿ç”¨ç‡: {max_memory:.1f}%")
        print(f"ç›‘æ§æ•°æ®ç‚¹æ•°é‡: {len(stats_history)}")

def main():
    """å‘½ä»¤è¡Œç›‘æ§å·¥å…·"""
    import argparse

    parser = argparse.ArgumentParser(description="Milvus èµ„æºç›‘æ§å·¥å…·")
    parser.add_argument("--interval", type=int, default=5, help="ç›‘æ§é—´éš”(ç§’)")
    parser.add_argument("--duration", type=int, default=60, help="ç›‘æ§æ—¶é•¿(ç§’)")
    parser.add_argument("--once", action="store_true", help="åªè·å–ä¸€æ¬¡çŠ¶æ€")

    args = parser.parse_args()

    monitor = ResourceMonitor()

    if args.once:
        # åªè·å–ä¸€æ¬¡çŠ¶æ€
        stats = monitor.get_container_stats()
        if stats:
            monitor.print_stats(stats)
        else:
            print("âŒ æ— æ³•è·å–å®¹å™¨çŠ¶æ€")
    else:
        # æŒç»­ç›‘æ§
        monitor.monitor_continuously(args.interval, args.duration)

if __name__ == "__main__":
    main()
```

## ğŸ³ Docker Compose é…ç½®ä¼˜åŒ–

åˆ›å»º `docker-compose.yml`ï¼ˆä¼˜åŒ–ç‰ˆï¼‰:

```yaml
version: '3.5'

services:
  milvus-standalone:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.3.3
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/milvus
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - milvus

  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd-data
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd-data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - milvus

  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    command: minio server /minio_data --console-address ":9001"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 30s
    ports:
      - "9001:9001"
    networks:
      - milvus

networks:
  milvus:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.23.0.0/24

volumes:
  milvus:
    driver: local
  etcd:
    driver: local
  minio:
    driver: local
```

## ğŸ“š å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Milvus å®˜æ–¹æ–‡æ¡£](https://milvus.io/docs)
- [PyMilvus SDK æ–‡æ¡£](https://milvus.io/api-reference/pymilvus/v2.3.x/About.md)
- [Milvus GitHub](https://github.com/milvus-io/milvus)

### æœ€ä½³å®è·µ
- [å‘é‡ç´¢å¼•é€‰æ‹©æŒ‡å—](https://milvus.io/docs/index.md)
- [æ€§èƒ½è°ƒä¼˜æŒ‡å—](https://milvus.io/docs/performance_faq.md)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å»ºè®®](https://milvus.io/docs/deploy_milvus.md)

### ç¤¾åŒºèµ„æº
- [Milvus ä¸­æ–‡ç¤¾åŒº](https://milvus.io/cn/)
- [æŠ€æœ¯åšå®¢](https://milvus.io/blog)
- [FAQ](https://milvus.io/docs/faq.md)

## ğŸ¯ ä¸‹ä¸€æ­¥

å®Œæˆ Milvus standalone éƒ¨ç½²åï¼Œå¯ä»¥ï¼š

1. **è¿è¡Œæµ‹è¯•è„šæœ¬**éªŒè¯éƒ¨ç½²æˆåŠŸ
2. **æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•**äº†è§£ç³»ç»Ÿèƒ½åŠ›
3. **å¼€å§‹å¼€å‘å‘é‡æœåŠ¡**é›†æˆåˆ°Agentç³»ç»Ÿ
4. **å‚è€ƒä¸»é¡¹ç›®è®¡åˆ’**ç»§ç»­ç¬¬ä¸€å‘¨çš„å…¶ä»–ä»»åŠ¡

è¿™ä¸ª standalone éƒ¨ç½²ä¸ºåç»­çš„å¼€å‘å·¥ä½œæä¾›äº†ç¨³å®šçš„åŸºç¡€ç¯å¢ƒï¼ğŸ‰

---

**ç‰ˆæœ¬**: v1.0
**æ›´æ–°æ—¶é—´**: 2025å¹´1æœˆ
**é€‚ç”¨ç‰ˆæœ¬**: Milvus v2.3.3
**ç»´æŠ¤**: å¼€å‘å›¢é˜Ÿ