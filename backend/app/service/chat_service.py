#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€èŠå¤©æœåŠ¡ - ä½¿ç”¨Milvusä½œä¸ºå‘é‡æ•°æ®åº“
æ•´åˆV1å’ŒV2ç‰ˆæœ¬åŠŸèƒ½ï¼ŒåŸºäºMilvusè¿›è¡Œæ–‡æ¡£æ£€ç´¢
"""

import json
import os
from typing import List, Dict, Any, Optional, Generator
import uuid
from openai import OpenAI
import numpy as np
import tiktoken

from .document_management_service import DocumentManagementService
from .web_search_service import WebSearchService
from .session_service import SessionService
from utils.database import default_manager
from models import Document
from service.core.rag.nlp.model import generate_embedding
from pymilvus import connections, Collection, utility

logger = __import__('logging').getLogger(__name__)


class UnifiedChatService:
    """
    ç»Ÿä¸€èŠå¤©æœåŠ¡

    åŠŸèƒ½ç‰¹æ€§ï¼š
    1. åŸºäºMilvusçš„å‘é‡æ£€ç´¢
    2. Webæœç´¢é›†æˆ
    3. ä¼šè¯ç®¡ç†
    4. æ–‡æ¡£é‡æ’åº
    5. æµå¼å“åº”ç”Ÿæˆ
    """

    def __init__(self, document_service: DocumentManagementService, web_search_service: WebSearchService, session_service: SessionService):
        """
        åˆå§‹åŒ–ç»Ÿä¸€èŠå¤©æœåŠ¡

        Args:
            document_service: æ–‡æ¡£ç®¡ç†æœåŠ¡
            web_search_service: Webæœç´¢æœåŠ¡
            session_service: ä¼šè¯ç®¡ç†æœåŠ¡
        """
        self.document_service = document_service
        self.web_search_service = web_search_service
        self.session_service = session_service

        # OpenAI/DashScopeé…ç½® - å®‰å…¨è¦æ±‚ï¼šå¿…é¡»è®¾ç½®APIå¯†é’¥
        self.openai_api_key = os.environ.get("DASHSCOPE_API_KEY")
        self.openai_base_url = os.environ.get("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        self.openai_model = os.environ.get("OPENAI_MODEL", "qwen-turbo")

        # å®‰å…¨éªŒè¯ï¼šAPIå¯†é’¥ä¸èƒ½ä¸ºç©º
        if not self.openai_api_key:
            raise ValueError("DASHSCOPE_API_KEY environment variable is required and cannot be empty")

        # Tokenè®¡ç®—
        self.encoding = tiktoken.get_encoding("cl100k_base")
        self.max_tokens = 12000

        # Milvusé…ç½®
        self.milvus_host = os.environ.get("MILVUS_HOST", "localhost")
        self.milvus_port = int(os.environ.get("MILVUS_PORT", "19530"))
        self.collection_name = "document_chunks"

        # åˆå§‹åŒ–Milvusè¿æ¥
        self._init_milvus()

    def _init_milvus(self):
        """åˆå§‹åŒ–Milvusè¿æ¥"""
        try:
            connections.connect(
                alias="default",
                host=self.milvus_host,
                port=self.milvus_port
            )

            # æ£€æŸ¥collectionæ˜¯å¦å­˜åœ¨
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
                self.collection.load()
                logger.info(f"âœ… å·²è¿æ¥åˆ°Milvusé›†åˆ: {self.collection_name}")
            else:
                logger.warning(f"âš ï¸ Milvusé›†åˆä¸å­˜åœ¨: {self.collection_name}")
                self.collection = None

        except Exception as e:
            logger.error(f"âŒ è¿æ¥Milvuså¤±è´¥: {e}")
            self.collection = None

    def retrieve_from_milvus(self, question: str, user_id: str = None, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        ä»Milvusæ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            question: ç”¨æˆ·é—®é¢˜
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤ç”¨æˆ·æ–‡æ¡£ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        if not self.collection:
            logger.error("Milvusè¿æ¥ä¸å¯ç”¨")
            return []

        try:
            # ç”Ÿæˆé—®é¢˜å‘é‡
            question_embedding = generate_embedding(question)

            # æ„å»ºæœç´¢å‚æ•°
            search_params = {
                "metric_type": "COSINE",
                "params": {"nprobe": 16}
            }

            # æ„å»ºè¡¨è¾¾å¼ï¼ˆå¯é€‰çš„ç”¨æˆ·è¿‡æ»¤ï¼‰
            expr = f"user_id == '{user_id}'" if user_id else None

            # æ‰§è¡Œå‘é‡æœç´¢
            results = self.collection.search(
                data=[question_embedding],
                anns_field="embedding",
                param=search_params,
                limit=top_k,
                expr=expr,
                output_fields=["content", "document_id", "chunk_id", "file_name", "user_id"]
            )

            # æ ¼å¼åŒ–ç»“æœ
            documents = []
            for hits in results:
                for hit in hits:
                    documents.append({
                        "content": hit.entity.get("content", ""),
                        "document_id": hit.entity.get("document_id", ""),
                        "chunk_id": hit.entity.get("chunk_id", ""),
                        "file_name": hit.entity.get("file_name", ""),
                        "user_id": hit.entity.get("user_id", ""),
                        "score": float(hit.score),
                        "source": "milvus"
                    })

            logger.info(f"ğŸ” ä»Milvusæ£€ç´¢åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£")
            return documents

        except Exception as e:
            logger.error(f"âŒ Milvusæ£€ç´¢å¤±è´¥: {e}")
            return []

    def retrieve_from_web(self, question: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """
        ä»Webæœç´¢è·å–ä¿¡æ¯

        Args:
            question: æœç´¢é—®é¢˜
            num_results: æœç´¢ç»“æœæ•°é‡

        Returns:
            Webæœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            results = self.web_search_service.search(question, num_results=num_results)

            web_docs = []
            for result in results:
                web_docs.append({
                    "title": result.get("title", ""),
                    "snippet": result.get("snippet", ""),
                    "url": result.get("url", ""),
                    "score": result.get("score", 0.0),
                    "source": "web"
                })

            logger.info(f"ğŸŒ ä»Webæœç´¢åˆ° {len(web_docs)} ä¸ªç»“æœ")
            return web_docs

        except Exception as e:
            logger.error(f"âŒ Webæœç´¢å¤±è´¥: {e}")
            return []

    def rerank_documents(self, question: str, documents: List[Dict[str, Any]], top_n: int = 10) -> List[Dict[str, Any]]:
        """
        é‡æ’åºæ–‡æ¡£

        Args:
            question: ç”¨æˆ·é—®é¢˜
            documents: æ–‡æ¡£åˆ—è¡¨
            top_n: è¿”å›æ–‡æ¡£æ•°é‡

        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not documents:
            return []

        try:
            # æŒ‰åˆ†æ•°æ’åº
            documents.sort(key=lambda x: x.get("score", 0), reverse=True)

            # è¿”å›å‰Nä¸ªæ–‡æ¡£
            return documents[:top_n]

        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£é‡æ’åºå¤±è´¥: {e}")
            return documents[:top_n]

    def _build_context(self, documents: List[Dict[str, Any]], max_tokens: int = 8000) -> str:
        """
        æ„å»ºä¸Šä¸‹æ–‡æ–‡æœ¬

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        context_parts = []
        current_tokens = 0

        for doc in documents:
            content = doc.get("content", "") or doc.get("snippet", "")
            if not content:
                continue

            # è®¡ç®—tokenæ•°é‡
            tokens = len(self.encoding.encode(content))

            if current_tokens + tokens > max_tokens:
                # æˆªæ–­æ–‡æ¡£å†…å®¹
                remaining_tokens = max_tokens - current_tokens
                if remaining_tokens > 100:  # è‡³å°‘ä¿ç•™100ä¸ªtoken
                    truncated = self.encoding.decode(self.encoding.encode(content)[:remaining_tokens])
                    context_parts.append(f"[{doc.get('source', 'unknown')}] {truncated}")
                break

            context_parts.append(f"[{doc.get('source', 'unknown')}] {content}")
            current_tokens += tokens

        return "\n\n".join(context_parts)

    def get_chat_completion(
        self,
        session_id: str,
        question: str,
        retrieved_content: List[Dict[str, Any]] = None
    ) -> Generator[str, None, None]:
        """
        ç”ŸæˆèŠå¤©å›å¤ï¼ˆæµå¼ï¼‰

        Args:
            session_id: ä¼šè¯ID
            question: ç”¨æˆ·é—®é¢˜
            retrieved_content: æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹

        Yields:
            æµå¼å›å¤å†…å®¹
        """
        try:
            # è·å–ä¼šè¯å†å²
            session_history = self.session_service.get_history(session_id)

            # æ„å»ºä¸Šä¸‹æ–‡
            context = ""
            if retrieved_content:
                context = self._build_context(retrieved_content)

            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ï¼š
{context}

è¯·æ ¹æ®ä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´æ˜ï¼Œå¹¶å°½å¯èƒ½æä¾›æœ‰ç”¨çš„å»ºè®®ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

å›ç­”ï¼š"""

            # è°ƒç”¨OpenAI APIç”Ÿæˆå›å¤
            client = OpenAI(
                api_key=self.openai_api_key,
                base_url=self.openai_base_url
            )

            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [
                {"role": "system", "content": system_prompt}
            ]

            # æ·»åŠ ä¼šè¯å†å²
            for msg in session_history[-10:]:  # æœ€è¿‘10æ¡æ¶ˆæ¯
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

            # æ·»åŠ å½“å‰é—®é¢˜
            messages.append({"role": "user", "content": question})

            # å‘é€æµå¼è¯·æ±‚
            response = client.chat.completions.create(
                model=self.openai_model,
                messages=messages,
                stream=True,
                temperature=0.7,
                max_tokens=2000
            )

            # æ”¶é›†å®Œæ•´å›å¤ç”¨äºä¿å­˜ä¼šè¯
            full_reply = ""

            # æµå¼è¾“å‡º
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_reply += content

                    # SSEæ ¼å¼è¾“å‡º
                    yield f"data: {json.dumps({'content': content, 'type': 'message'}, ensure_ascii=False)}\n\n"

            # ä¿å­˜ä¼šè¯
            self.session_service.add_message(session_id, "user", question)
            self.session_service.add_message(session_id, "assistant", full_reply)

            # ç»“æŸæ ‡è®°
            yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"

        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆèŠå¤©å›å¤å¤±è´¥: {e}")
            yield f"data: {json.dumps({'error': str(e), 'type': 'error'}, ensure_ascii=False)}\n\n"