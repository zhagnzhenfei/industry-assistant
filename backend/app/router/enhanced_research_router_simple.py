"""
ç®€åŒ–ç‰ˆå¢å¼ºç ”ç©¶æŠ¥å‘ŠAPIè·¯ç”±
æµå¼è¾“å‡ºæ‰§è¡Œè¿‡ç¨‹ï¼Œå®æ—¶å±•ç¤ºç ”ç©¶è§„åˆ’ã€æ‰§è¡Œæ­¥éª¤å’Œæœ€ç»ˆç»“æœ
"""
import logging
from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, List, AsyncGenerator
from datetime import datetime
import asyncio
import json

from services.research_service import execute_research_task_stream, save_research_memory
from services.agent_orchestration.odr_orchestrator import ResearchResult
from service.auth_service import get_current_user
from models.user_models import User

logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/enhanced-research", tags=["enhanced-research"])


class EnhancedResearchRequest(BaseModel):
    """å¢å¼ºç‰ˆç ”ç©¶æŠ¥å‘Šè¯·æ±‚æ¨¡å‹"""
    question: str = Field(..., description="ç ”ç©¶é—®é¢˜", min_length=5, max_length=500)
    user_context: Optional[Dict[str, Any]] = Field(default=None, description="ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯")
    allow_clarification: bool = Field(default=False, description="æ˜¯å¦å…è®¸è¯·æ±‚æ¾„æ¸…")
    research_depth: str = Field(default="comprehensive", description="ç ”ç©¶æ·±åº¦: basic/standard/comprehensive")
    memory_mode: str = Field(default="smart", description="è®°å¿†æ¨¡å¼: none/short_term/long_term/smart")
    previous_context_ids: Optional[List[str]] = Field(default=None, description="å…³è”çš„å†å²ç ”ç©¶ID")


class ResearchReportResponse(BaseModel):
    """ç ”ç©¶æŠ¥å‘Šå“åº”æ¨¡å‹"""
    research_id: str
    question: str
    status: str
    final_report: str
    key_findings: List[str]
    metadata: Dict[str, Any]
    quality_score: float
    duration: float
    created_at: str


@router.post("/generate")
async def generate_enhanced_research_report(
    request: EnhancedResearchRequest,
    current_user: User = Depends(get_current_user)  # å¿…é¡»è®¤è¯
):
    """
    ç”Ÿæˆå¢å¼ºç‰ˆæ·±åº¦ç ”ç©¶æŠ¥å‘Šï¼ˆå¸¦è®°å¿†åŠŸèƒ½ï¼‰
    
    æ³¨æ„ï¼šæ­¤æ¥å£éœ€è¦JWTè®¤è¯ï¼Œä¸æ”¯æŒåŒ¿åè®¿é—®
    """
    research_id = f"research_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(request.question) % 10000}"

    # è·å–ç”¨æˆ·IDï¼ˆå¿…é¡»è®¤è¯ï¼Œæ‰€ä»¥ä¸€å®šæœ‰user_idï¼‰
    user_id = current_user.user_id

    logger.info(f"ğŸš€ [REQUEST_START] å¼€å§‹å¤„ç†ç ”ç©¶è¯·æ±‚ {research_id}")
    logger.info(f"ğŸ“ [REQUEST_INFO] é—®é¢˜: {request.question}")
    logger.info(f"âš™ï¸ [REQUEST_CONFIG] æ¾„æ¸…={request.allow_clarification}, æ·±åº¦={request.research_depth}")
    logger.info(f"ğŸ§  [MEMORY] è®°å¿†æ¨¡å¼: {request.memory_mode}, ç”¨æˆ·: {user_id}")

    # è®°å¿†æœåŠ¡åˆå§‹åŒ–
    from services.memory.memory_factory import get_memory_service
    memory_service = get_memory_service()

    # å¢å¼ºç”¨æˆ·ä¸Šä¸‹æ–‡
    enriched_context = request.user_context or {}
    enriched_context["user_id"] = user_id
    enriched_context["memory_mode"] = request.memory_mode

    # å¦‚æœå¯ç”¨è®°å¿†ä¸”æœ‰æœ‰æ•ˆæœåŠ¡ï¼ŒåŠ è½½ç”¨æˆ·è®°å¿†
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ç®€åŒ–å®ç°ï¼Œç¬¬å››é˜¶æ®µå¯ä»¥ä½¿ç”¨ MemoryModeStrategy ç±»ä¼˜åŒ–
    if request.memory_mode != "none" and memory_service:
        try:
            logger.info(f"ğŸ§  [MEMORY] æ­£åœ¨åŠ è½½ç”¨æˆ·è®°å¿†ï¼Œæ¨¡å¼: {request.memory_mode}")
            
            if request.memory_mode == "smart":
                # smart æ¨¡å¼ï¼šæœç´¢ç›¸å…³è®°å¿†ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
                user_memories = await memory_service.search_memories(
                    user_id=user_id,
                    query=request.question,
                    limit=10
                )
            elif request.memory_mode == "short_term":
                # short_term æ¨¡å¼ï¼šè·å–æœ€è¿‘è®°å¿†ï¼ˆç®€åŒ–ç‰ˆï¼Œç¬¬å››é˜¶æ®µå¯ä»¥ä½¿ç”¨ç­–ç•¥ç±»ä¼˜åŒ–ï¼‰
                all_memories = await memory_service.get_all_memories(user_id, limit=20)
                user_memories = all_memories[:10]  # ç®€åŒ–ï¼šå–å‰10æ¡
            elif request.memory_mode == "long_term":
                # long_term æ¨¡å¼ï¼šè·å–æ‰€æœ‰å†å²è®°å¿†
                user_memories = await memory_service.get_all_memories(user_id, limit=20)
            else:  # none
                user_memories = []
            
            enriched_context["user_memories"] = user_memories
            enriched_context["memory_loaded"] = True
            logger.info(f"âœ… [MEMORY] è®°å¿†åŠ è½½å®Œæˆï¼Œæ‰¾åˆ° {len(user_memories)} æ¡è®°å¿†")
        except Exception as e:
            logger.warning(f"âš ï¸ [MEMORY] è®°å¿†åŠ è½½å¤±è´¥: {e}ï¼Œç»§ç»­æ— è®°å¿†æ‰§è¡Œ")
            enriched_context["user_memories"] = []
            enriched_context["memory_loaded"] = False
    
    async def generate_research_stream():
        """ç”Ÿæˆç ”ç©¶æµå¼å“åº”"""
        try:
            final_result = None  # ç”¨äºä¿å­˜æœ€ç»ˆç ”ç©¶ç»“æœ
            
            # å‘é€åˆå§‹ä¿¡æ¯
            initial_data = {
                'type': 'start',
                'research_id': research_id,
                'question': request.question,
                'message': 'ğŸš€ å¼€å§‹å¤„ç†ç ”ç©¶è¯·æ±‚',
                'timestamp': datetime.now().isoformat()
            }
            logger.info(f"ğŸ“¤ [STREAM_SEND] {research_id}: {initial_data['message']}")
            yield f"data: {json.dumps(initial_data, ensure_ascii=False)}\n\n"
            
            # æ‰§è¡Œç ”ç©¶ä»»åŠ¡ï¼ˆæµå¼ï¼‰ï¼Œä½¿ç”¨å¢å¼ºçš„ä¸Šä¸‹æ–‡å’Œè®°å¿†æ¨¡å¼
            async for progress_data in execute_research_task_stream(
                research_id=research_id,
                question=request.question,
                user_context=enriched_context,
                allow_clarification=request.allow_clarification,
                research_depth=request.research_depth,
                memory_mode=request.memory_mode,
                memory_service=memory_service
            ):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœ
                if progress_data.get('type') == 'result':
                    # ä»è¿›åº¦æ•°æ®ä¸­æå– ResearchResult å¯¹è±¡
                    # execute_research_task_stream å·²åœ¨ progress_data ä¸­æ·»åŠ  'final_result' å­—æ®µ
                    final_result = progress_data.get('final_result')
                    if not final_result:
                        # å¦‚æœ execute_research_task_stream æ²¡æœ‰æ·»åŠ ï¼Œåˆ™ä» 'result' å­—æ®µæå–
                        final_result_data = progress_data.get('result')
                        if final_result_data:
                            final_result = final_result_data if isinstance(final_result_data, ResearchResult) else ResearchResult(
                                question=final_result_data.get('question', request.question),
                                final_report=final_result_data.get('final_report', ''),
                                status=final_result_data.get('status', 'completed'),
                                key_findings=final_result_data.get('key_findings', []),
                                raw_notes=final_result_data.get('raw_notes', []),
                                metadata=final_result_data.get('metadata', {}),
                                progress=final_result_data.get('progress', 100.0)
                            )
                
                # æ ¹æ®æ•°æ®ç±»å‹è®°å½•ä¸åŒçš„æ—¥å¿—
                if progress_data.get('type') == 'progress':
                    logger.info(f"ğŸ“Š [STREAM_PROGRESS] {research_id}: {progress_data.get('message', '')} ({progress_data.get('progress', 0):.1f}%)")
                elif progress_data.get('type') == 'result':
                    logger.info(f"ğŸ“‹ [STREAM_RESULT] {research_id}: ç ”ç©¶å®Œæˆï¼Œè´¨é‡è¯„åˆ† {progress_data.get('quality_score', 0):.1f}åˆ†")
                    logger.info(f"ğŸ“„ [STREAM_REPORT] {research_id}: æŠ¥å‘Šé•¿åº¦ {len(progress_data.get('final_report', ''))} å­—ç¬¦")
                else:
                    logger.info(f"ğŸ“¤ [STREAM_SEND] {research_id}: {progress_data.get('message', 'Unknown message')}")
                
                yield f"data: {json.dumps(progress_data, ensure_ascii=False)}\n\n"
            
            # å¼‚æ­¥ä¿å­˜ç ”ç©¶è®°å¿†ï¼ˆä¸é˜»å¡å“åº”ï¼‰
            # æ³¨æ„ï¼šåªæœ‰åœ¨æœ‰æœ€ç»ˆç»“æœä¸”å¯ç”¨è®°å¿†æ—¶æ‰ä¿å­˜
            if request.memory_mode != "none" and memory_service and final_result:
                asyncio.create_task(save_research_memory(
                    user_id=user_id,
                    research_id=research_id,
                    question=request.question,
                    result=final_result,
                    memory_service=memory_service
                ))
                logger.info(f"ğŸ’¾ [MEMORY] å·²å¯åŠ¨å¼‚æ­¥è®°å¿†ä¿å­˜ä»»åŠ¡: {research_id}")
            
            # å‘é€å®Œæˆä¿¡æ¯
            complete_data = {
                'type': 'complete',
                'research_id': research_id,
                'message': 'âœ… ç ”ç©¶ä»»åŠ¡å®Œæˆ',
                'timestamp': datetime.now().isoformat()
            }
            logger.info(f"âœ… [STREAM_COMPLETE] {research_id}: æµå¼å“åº”å®Œæˆ")
            yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            logger.error(f"ğŸ’¥ [STREAM_FAILED] {research_id}: æµå¼å“åº”å¤±è´¥: {e}")
            import traceback
            logger.error(f"ğŸ” [STREAM_ERROR] {research_id}: å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            
            error_data = {
                'type': 'error',
                'research_id': research_id,
                'message': f'ç ”ç©¶è¯·æ±‚å¤±è´¥: {str(e)}',
                'timestamp': datetime.now().isoformat()
            }
            logger.error(f"ğŸ“¤ [STREAM_ERROR] {research_id}: å‘é€é”™è¯¯å“åº”")
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_research_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}
