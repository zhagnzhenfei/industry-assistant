from typing import Dict, Any, Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from starlette.status import HTTP_200_OK, HTTP_400_BAD_REQUEST, HTTP_500_INTERNAL_SERVER_ERROR

from service import ResearchService, ServiceConfig
from service.dr_g import serialize_event  # å¯¼å…¥åºåˆ—åŒ–å‡½æ•°

# è®°å¿†åŠŸèƒ½æ”¯æŒï¼ˆæ–°å¢ï¼‰
try:
    from services.memory.decorators import research_memory
    from service.auth_service import get_current_user
    from models.user_models import User
    MEMORY_ENABLED = True
except ImportError:
    # å¦‚æœè®°å¿†æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç©ºè£…é¥°å™¨
    def research_memory(*args, **kwargs):
        def decorator(func):
            return func
        return decorator
    MEMORY_ENABLED = False

# åˆ›å»ºè·¯ç”±å®ä¾‹
router = APIRouter(prefix="/research", tags=["research"])

# è¯·æ±‚æ¨¡å‹
class ResearchRequest(BaseModel):
    """æ·±åº¦ç ”ç©¶è¯·æ±‚æ¨¡å‹"""
    query: str
    max_iterations: Optional[int] = 3
    memory_mode: Optional[str] = "smart"  # æ–°å¢è®°å¿†æ¨¡å¼æ”¯æŒ

    class Config:
        schema_extra = {
            "example": {
                "query": "ä¸­å›½å®‰è´£é™©çš„å¸‚åœºç°çŠ¶å’Œæœªæ¥å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿè¯·æä¾›å…·ä½“æ•°æ®æ”¯æŒã€‚",
                "max_iterations": 3,
                "memory_mode": "smart"
            }
        }

# è·å–æœåŠ¡å®ä¾‹
def get_research_service():
    """è·å–ç ”ç©¶æœåŠ¡å®ä¾‹"""
    config = ServiceConfig.get_api_config()
    research_service = ResearchService(
        search_api_key=config.get('bochaai_api_key'),
        llm_api_key=config.get('dashscope_api_key'),
        llm_base_url=config.get('dashscope_base_url')
    )
    return {"research_service": research_service}

@router.post("/stream", status_code=HTTP_200_OK)
async def stream_research(
    request: ResearchRequest,
    services: Dict[str, Any] = Depends(get_research_service)
):
    """
    æ·±åº¦ç ”ç©¶æ¥å£ - æµå¼è¾“å‡º

    å¯¹ç”¨æˆ·çš„ç ”ç©¶é—®é¢˜æ‰§è¡Œå…¨é¢çš„æ·±åº¦ç ”ç©¶ï¼ŒåŒ…æ‹¬é—®é¢˜åˆ†è§£ã€ç½‘ç»œæœç´¢ã€ä¿¡æ¯æ•´åˆã€æ•°æ®åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆã€‚
    ä½¿ç”¨ Server-Sent Events (SSE) æ ¼å¼æµå¼è¿”å›æ•´ä¸ªç ”ç©¶è¿‡ç¨‹å’Œç»“æœã€‚

    Args:
        request: åŒ…å«ç ”ç©¶é—®é¢˜å’Œé…ç½®çš„è¯·æ±‚ä½“

    Returns:
        æµå¼å“åº”ï¼ŒåŒ…å«ç ”ç©¶è¿‡ç¨‹å’Œç»“æœçš„ SSE æ ¼å¼æ•°æ®
    """
    research_service = services["research_service"]

    async def generate_sse():
        try:
            async for event in research_service.research_stream(
                query=request.query,
                max_iterations=request.max_iterations
            ):
                # å°†äº‹ä»¶è½¬æ¢ä¸º SSE æ ¼å¼
                yield f"data: {event}\n\n"
        except Exception as e:
            # ä½¿ç”¨serialize_eventè¿›è¡Œé”™è¯¯å¤„ç†ï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®
            error_event = serialize_event({"type": "error", "content": str(e)})
            yield f"data: {error_event}\n\n"

    return StreamingResponse(
        generate_sse(),
        media_type="text/event-stream"
    )


@router.post("/stream-with-memory", status_code=HTTP_200_OK)
@research_memory(
    memory_mode_param="memory_mode",
    user_context_param="enhanced_context",
    auto_save=True
)
async def stream_research_with_memory(
    request: ResearchRequest,
    services: Dict[str, Any] = Depends(get_research_service),
    current_user: User = Depends(get_current_user) if MEMORY_ENABLED else None,
    enhanced_context: Optional[Dict[str, Any]] = None
):
    """
    æ·±åº¦ç ”ç©¶æ¥å£ - æ”¯æŒè®°å¿†åŠŸèƒ½çš„æµå¼è¾“å‡º

    åœ¨åŸæœ‰ç ”ç©¶åŠŸèƒ½åŸºç¡€ä¸Šï¼Œå¢åŠ äº†è®°å¿†æ”¯æŒï¼š
    - è‡ªåŠ¨åŠ è½½ç”¨æˆ·ç›¸å…³çš„ç ”ç©¶å†å²
    - åŸºäºå†å²è®°å¿†æä¾›æ›´ç›¸å…³çš„ç ”ç©¶ç»“æœ
    - è‡ªåŠ¨ä¿å­˜æ–°çš„ç ”ç©¶æˆæœåˆ°è®°å¿†ä¸­

    Args:
        request: åŒ…å«ç ”ç©¶é—®é¢˜ã€é…ç½®å’Œè®°å¿†æ¨¡å¼çš„è¯·æ±‚ä½“
        current_user: å½“å‰è®¤è¯ç”¨æˆ·
        enhanced_context: å¢å¼ºçš„ä¸Šä¸‹æ–‡ï¼ˆç”±è®°å¿†è£…é¥°å™¨æ³¨å…¥ï¼‰

    Returns:
        æµå¼å“åº”ï¼ŒåŒ…å«ç ”ç©¶è¿‡ç¨‹å’Œç»“æœçš„ SSE æ ¼å¼æ•°æ®
    """
    research_service = services["research_service"]

    # ä½¿ç”¨å¢å¼ºçš„æŸ¥è¯¢ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    query = request.query
    if enhanced_context and enhanced_context.get("has_memories"):
        # å¯ä»¥åŸºäºå†å²è®°å¿†è°ƒæ•´æŸ¥è¯¢
        memory_context = enhanced_context.get("memory_context", "")
        if memory_context:
            # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æŸ¥è¯¢å¢å¼ºé€»è¾‘
            # ç›®å‰åªæ˜¯è®°å½•æ—¥å¿—
            import logging
            logger = logging.getLogger(__name__)
            logger.info(f"ğŸ§  [RESEARCH_WITH_MEMORY] ä½¿ç”¨ {enhanced_context.get('memory_count', 0)} æ¡å†å²è®°å¿†")

    async def generate_sse():
        try:
            # ç”Ÿæˆç ”ç©¶IDç”¨äºè®°å¿†ä¿å­˜
            import datetime
            research_id = f"research_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(query) % 10000}"

            async for event in research_service.research_stream(
                query=query,
                max_iterations=request.max_iterations
            ):
                # æ·»åŠ è®°å¿†ä¿¡æ¯åˆ°äº‹ä»¶ä¸­
                if enhanced_context and enhanced_context.get("has_memories"):
                    try:
                        import json
                        event_dict = json.loads(event)
                        event_dict["memory_info"] = {
                            "enabled": True,
                            "count": enhanced_context.get("memory_count", 0),
                            "research_id": research_id
                        }
                        event = json.dumps(event_dict, ensure_ascii=False)
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸäº‹ä»¶
                        pass

                # å°†äº‹ä»¶è½¬æ¢ä¸º SSE æ ¼å¼
                yield f"data: {event}\n\n"

        except Exception as e:
            # ä½¿ç”¨serialize_eventè¿›è¡Œé”™è¯¯å¤„ç†ï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®
            error_event = serialize_event({"type": "error", "content": str(e)})
            yield f"data: {error_event}\n\n"

    return StreamingResponse(
        generate_sse(),
        media_type="text/event-stream"
    )

@router.get("/stream", status_code=HTTP_200_OK)
async def stream_research_get(
    query: str = Query(..., description="ç ”ç©¶é—®é¢˜", example="ä¸­å›½å®‰è´£é™©çš„å¸‚åœºç°çŠ¶å’Œæœªæ¥å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"),
    max_iterations: int = Query(3, description="æœ€å¤§è¿­ä»£æ¬¡æ•°", ge=1, le=5),
    services: Dict[str, Any] = Depends(get_research_service)
):
    """
    æ·±åº¦ç ”ç©¶æ¥å£ - GETæ–¹å¼æµå¼è¾“å‡º
    
    å¯¹ç”¨æˆ·çš„ç ”ç©¶é—®é¢˜æ‰§è¡Œå…¨é¢çš„æ·±åº¦ç ”ç©¶ï¼ŒåŒ…æ‹¬é—®é¢˜åˆ†è§£ã€ç½‘ç»œæœç´¢ã€ä¿¡æ¯æ•´åˆã€æ•°æ®åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆã€‚
    ä½¿ç”¨ Server-Sent Events (SSE) æ ¼å¼æµå¼è¿”å›æ•´ä¸ªç ”ç©¶è¿‡ç¨‹å’Œç»“æœã€‚
    
    Args:
        query: ç ”ç©¶é—®é¢˜
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆèŒƒå›´ï¼š1-5ï¼‰
        
    Returns:
        æµå¼å“åº”ï¼ŒåŒ…å«ç ”ç©¶è¿‡ç¨‹å’Œç»“æœçš„ SSE æ ¼å¼æ•°æ®
    """
    research_service = services["research_service"]
    
    async def generate_sse():
        try:
            async for event in research_service.research_stream(
                query=query,
                max_iterations=max_iterations
            ):
                # å°†äº‹ä»¶è½¬æ¢ä¸º SSE æ ¼å¼
                yield f"data: {event}\n\n"
        except Exception as e:
            # ä½¿ç”¨serialize_eventè¿›è¡Œé”™è¯¯å¤„ç†ï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®
            error_event = serialize_event({"type": "error", "content": str(e)})
            yield f"data: {error_event}\n\n"
    
    return StreamingResponse(
        generate_sse(),
        media_type="text/event-stream"
    ) 