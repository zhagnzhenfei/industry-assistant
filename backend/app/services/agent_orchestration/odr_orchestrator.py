"""
Open Deep Research ç¼–æ’å™¨
åŸºäºå®˜æ–¹æ–‡æ¡£çš„å®Œæ•´ç¼–æ’å™¨å®ç°
"""
import asyncio
import logging
import os
from typing import Dict, Any, List, Optional, Callable, AsyncGenerator
from datetime import datetime
from dataclasses import dataclass, field

from langchain_core.messages import HumanMessage

from .odr_main import deep_researcher
from .odr_configuration import Configuration

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv æœªå®‰è£…ï¼Œè·³è¿‡

logger = logging.getLogger(__name__)

# é…ç½®æ—¥å¿—
if not logger.handlers:
    # é˜²æ­¢æ—¥å¿—é‡å¤
    logger.propagate = False
    
    # æ ¹æ®ç¯å¢ƒå˜é‡è®¾ç½®æ—¥å¿—çº§åˆ«
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    logger.setLevel(getattr(logging, log_level, logging.INFO))
    
    # æ·»åŠ æ§åˆ¶å° handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(getattr(logging, log_level, logging.INFO))
    
    # è®¾ç½®æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)


@dataclass
class ResearchResult:
    """ç ”ç©¶ç»“æœæ•°æ®ç±» - å‘åå…¼å®¹çš„ç®€åŒ–ç‰ˆæœ¬"""
    question: str
    final_report: Optional[str] = None
    status: str = "initializing"
    key_findings: List[str] = field(default_factory=list)
    raw_notes: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    progress: float = 0.0


class ODRResearchOrchestrator:
    """Open Deep Research ç¼–æ’å™¨ - åŸºäºå®˜æ–¹æ¶æ„"""

    def __init__(self, config: Optional[Configuration] = None):
        self.config = config or Configuration(
            allow_clarification=True,
            search_api="serper"
        )

        # ä½¿ç”¨å·²ç¼–è¯‘çš„å›¾
        self.graph = deep_researcher
        self.initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–ç¼–æ’å™¨"""
        try:
            self.initialized = True
            logger.info("Open Deep Research ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"ç¼–æ’å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.initialized = False
            logger.info("Open Deep Research ç¼–æ’å™¨èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")

    async def process_research_request(
        self,
        question: str,
        user_context: Optional[Dict[str, Any]] = None,
        allow_clarification: bool = True,
        progress_callback: Optional[Callable] = None
    ) -> ResearchResult:
        """
        å¤„ç†ç ”ç©¶è¯·æ±‚çš„ä¸»è¦å…¥å£

        Args:
            question: ç ”ç©¶é—®é¢˜
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡
            allow_clarification: æ˜¯å¦å…è®¸æ¾„æ¸…
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            ResearchResult: ç ”ç©¶ç»“æœ
        """
        logger.info("=== å¼€å§‹å¤„ç†ç ”ç©¶è¯·æ±‚ ===")
        
        if not self.initialized:
            logger.info("ç¼–æ’å™¨æœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
            await self.initialize()

        start_time = datetime.now()

        try:
            logger.info(f"ç ”ç©¶é—®é¢˜: {question}")
            logger.info(f"å…è®¸æ¾„æ¸…: {allow_clarification}")

            # æ›´æ–°é…ç½®
            if allow_clarification != self.config.allow_clarification:
                logger.info(f"æ›´æ–°æ¾„æ¸…é…ç½®: {allow_clarification}")
                self.config.allow_clarification = allow_clarification

            # åˆ›å»ºé…ç½®
            config = {
                "configurable": {
                    "thread_id": f"research_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(question) % 10000}",
                    **self.config.model_dump()
                }
            }
            logger.info(f"è¿è¡Œé…ç½®: {config}")

            # æ›´æ–°è¿›åº¦
            if progress_callback:
                logger.info("è°ƒç”¨è¿›åº¦å›è°ƒ: 5%")
                progress_callback(5.0)  # åˆå§‹åŒ–å®Œæˆ

            # æ‰§è¡Œç ”ç©¶
            initial_state = {
                "messages": [HumanMessage(content=question)]
            }
            logger.info(f"åˆå§‹çŠ¶æ€: {initial_state}")

            # æ‰§è¡Œç ”ç©¶ä»»åŠ¡
            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œç ”ç©¶ä»»åŠ¡...")
            final_state = await self.graph.ainvoke(initial_state, config)
            logger.info(f"âœ… ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {final_state}")

            # æ›´æ–°è¿›åº¦
            if progress_callback:
                logger.info("è°ƒç”¨è¿›åº¦å›è°ƒ: 100%")
                progress_callback(100.0)  # å®Œæˆ

            # è½¬æ¢ä¸ºç®€åŒ–çš„ResearchResultæ ¼å¼
            logger.info("è½¬æ¢ç ”ç©¶ç»“æœ...")
            result = self._convert_to_research_result(final_state, start_time)

            logger.info(f"ç ”ç©¶è¯·æ±‚å¤„ç†å®Œæˆï¼Œè€—æ—¶: {result.metadata.get('duration', 0):.2f}ç§’")
            logger.info("=== ç ”ç©¶è¯·æ±‚å¤„ç†å®Œæˆ ===")
            return result

        except Exception as e:
            import traceback
            error_traceback = traceback.format_exc()
            logger.error(f"ç ”ç©¶è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
            logger.error(f"å®Œæ•´é”™è¯¯ä¿¡æ¯: {error_traceback}")
            return ResearchResult(
                question=question,
                status="failed",
                metadata={
                    "error": str(e),
                    "traceback": error_traceback,
                    "duration": (datetime.now() - start_time).total_seconds()
                }
            )

    async def process_research_request_stream(
        self,
        question: str,
        user_context: Optional[Dict[str, Any]] = None,
        allow_clarification: bool = True
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†ç ”ç©¶è¯·æ±‚ï¼Œå®æ—¶è¾“å‡ºæ¯ä¸ªå…³é”®æ­¥éª¤çš„è¿›åº¦
        
        Args:
            question: ç ”ç©¶é—®é¢˜
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡
            allow_clarification: æ˜¯å¦å…è®¸æ¾„æ¸…
            
        Yields:
            è¿›åº¦æ•°æ®å­—å…¸:
            {
                'type': 'progress',      # è¿›åº¦æ›´æ–°
                'stage': 'å½“å‰é˜¶æ®µ',
                'progress': è¿›åº¦ç™¾åˆ†æ¯”,   # 0-100
                'message': 'ç”¨æˆ·å¯è¯»æ¶ˆæ¯',
                'details': 'è¯¦ç»†ä¿¡æ¯',
                'metadata': {
                    'node_name': 'èŠ‚ç‚¹åç§°',
                    'event_type': 'äº‹ä»¶ç±»å‹'
                }
            }
            æˆ–:
            {
                'type': 'result',        # æœ€ç»ˆç»“æœ
                'final_report': '...',
                'key_findings': [...],
                ...
            }
        """
        logger.info("=== å¼€å§‹æµå¼å¤„ç†ç ”ç©¶è¯·æ±‚ ===")
        
        if not self.initialized:
            logger.info("ç¼–æ’å™¨æœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
            await self.initialize()
        
        start_time = datetime.now()
        
        try:
            logger.info(f"ç ”ç©¶é—®é¢˜: {question}")
            logger.info(f"å…è®¸æ¾„æ¸…: {allow_clarification}")
            
            # æ›´æ–°é…ç½®
            if allow_clarification != self.config.allow_clarification:
                logger.info(f"æ›´æ–°æ¾„æ¸…é…ç½®: {allow_clarification}")
                self.config.allow_clarification = allow_clarification
            
            # åˆ›å»ºé…ç½®
            config = {
                "configurable": {
                    "thread_id": f"research_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(question) % 10000}",
                    **self.config.model_dump()
                }
            }
            
            # åˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=question)]
            }
            
            # è¿›åº¦è¿½è¸ªå™¨
            progress_tracker = {
                'current_node': None,
                'supervisor_round': 0,
                'researcher_count': 0,
                'base_progress': 0.0,
                'last_progress': 0.0,
                # æ¶ˆæ¯è¿‡æ»¤å™¨
                'last_ai_message_time': 0,
                'ai_message_cooldown': 2.0,  # AIæ¶ˆæ¯å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
                'search_count': 0,
                'last_message_type': None,
                'start_time': datetime.now().timestamp()
            }
            
            # ä¿å­˜æœ€ç»ˆçŠ¶æ€
            final_state = None
            
            # â­ æ ¸å¿ƒï¼šä½¿ç”¨ astream_events æµå¼æ‰§è¡Œ
            logger.info("ğŸš€ å¼€å§‹æµå¼æ‰§è¡Œç ”ç©¶ä»»åŠ¡...")
            async for event in self.graph.astream_events(
                initial_state, 
                config, 
                version="v2"
            ):
                # è§£æäº‹ä»¶å¹¶ç”Ÿæˆè¿›åº¦æ•°æ®
                progress_data = self._parse_event_to_progress(
                    event, 
                    progress_tracker
                )
                
                if progress_data:
                    yield progress_data
                
                # ä¿å­˜æœ€ç»ˆçŠ¶æ€ï¼ˆä» on_chain_end çš„ LangGraph ä¸»èŠ‚ç‚¹è·å–ï¼‰
                if (event.get("event") == "on_chain_end" and 
                    event.get("name") == "LangGraph" and 
                    "output" in event.get("data", {})):
                    final_state = event["data"]["output"]
            
            # è½¬æ¢ä¸ºResearchResult
            if final_state:
                result = self._convert_to_research_result(final_state, start_time)
                
                # å‘é€æœ€ç»ˆç»“æœ
                yield {
                    'type': 'result',
                    'stage': 'completed',
                    'progress': 100.0,
                    'message': 'âœ… ç ”ç©¶ä»»åŠ¡å®Œæˆï¼',
                    'research_id': config["configurable"]["thread_id"],
                    'question': question,
                    'status': result.status,
                    'final_report': result.final_report or "ç ”ç©¶æœªå®Œæˆ",
                    'key_findings': result.key_findings,
                    'metadata': result.metadata,
                    'duration': result.metadata.get('duration', 0)
                }
                
                logger.info(f"æµå¼ç ”ç©¶å®Œæˆï¼Œè€—æ—¶: {result.metadata.get('duration', 0):.2f}ç§’")
            else:
                logger.warning("æœªè·å–åˆ°æœ€ç»ˆçŠ¶æ€")
                yield {
                    'type': 'error',
                    'message': 'æœªèƒ½è·å–ç ”ç©¶ç»“æœ',
                    'error': 'No final state'
                }
            
            logger.info("=== æµå¼ç ”ç©¶è¯·æ±‚å¤„ç†å®Œæˆ ===")
            
        except Exception as e:
            import traceback
            error_traceback = traceback.format_exc()
            logger.error(f"æµå¼ç ”ç©¶å¤±è´¥: {e}")
            logger.error(f"å®Œæ•´é”™è¯¯ä¿¡æ¯: {error_traceback}")
            
            yield {
                'type': 'error',
                'stage': 'failed',
                'message': f'âŒ ç ”ç©¶å¤±è´¥: {str(e)}',
                'error': str(e),
                'traceback': error_traceback
            }

    def _get_stats_summary(self, tracker: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
        current_time = datetime.now().timestamp()
        elapsed_time = int(current_time - tracker.get('start_time', current_time))
        search_count = tracker.get('search_count', 0)
        researcher_count = tracker.get('researcher_count', 0)
        supervisor_round = tracker.get('supervisor_round', 0)
        
        parts = []
        parts.append(f"å·²è¿è¡Œ {elapsed_time}ç§’")
        if supervisor_round > 0:
            parts.append(f"ç¬¬{supervisor_round}è½®è§„åˆ’")
        if researcher_count > 0:
            parts.append(f"{researcher_count}ä¸ªç ”ç©¶å•å…ƒ")
        if search_count > 0:
            parts.append(f"{search_count}æ¬¡æœç´¢")
        
        return " | ".join(parts)
    
    def _parse_event_to_progress(
        self, 
        event: Dict[str, Any], 
        tracker: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        å°† LangGraph äº‹ä»¶è§£æä¸ºè¿›åº¦æ•°æ®
        
        Args:
            event: LangGraph äº‹ä»¶
            tracker: è¿›åº¦è¿½è¸ªå™¨ï¼Œç”¨äºè®°å½•çŠ¶æ€
            
        Returns:
            è¿›åº¦æ•°æ®å­—å…¸ï¼Œå¦‚æœä¸éœ€è¦è¾“å‡ºåˆ™è¿”å› None
        """
        event_type = event.get("event")
        event_name = event.get("name", "")
        
        # DEBUG çº§åˆ«ï¼šè¾“å‡ºå®Œæ•´äº‹ä»¶æ•°æ®
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"[EVENT] {event_type} | {event_name}")
            # logger.debug(f"[EVENT_DATA] {event}")  # âœ… å·²éªŒè¯åŠŸèƒ½æ­£å¸¸ï¼Œæ³¨é‡Šæ‰ä»¥å‡å°‘æ—¥å¿—å†—ä½™
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if event_type == "on_chain_start":
            tracker['current_node'] = event_name
            
            # ä¸»å·¥ä½œæµèŠ‚ç‚¹
            if event_name == "clarify_with_user":
                tracker['base_progress'] = 0.0
                return {
                    'type': 'progress',
                    'stage': 'clarifying',
                    'progress': 0.0,
                    'message': 'ğŸ¤” æ£€æŸ¥é—®é¢˜æ˜¯å¦éœ€è¦æ¾„æ¸…',
                    'details': 'åˆ†æé—®é¢˜æ¸…æ™°åº¦ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç”¨æˆ·è¡¥å……ä¿¡æ¯',
                    'metadata': {'node': 'clarify_with_user', 'event': 'start'}
                }
            
            elif event_name == "write_research_brief":
                tracker['base_progress'] = 5.0
                return {
                    'type': 'progress',
                    'stage': 'planning',
                    'progress': 5.0,
                    'message': 'ğŸ“ è§„åˆ’ç ”ç©¶ç­–ç•¥',
                    'details': 'å°†é—®é¢˜è½¬æ¢ä¸ºç»“æ„åŒ–çš„ç ”ç©¶ç®€æŠ¥',
                    'metadata': {'node': 'write_research_brief', 'event': 'start'}
                }
            
            elif event_name == "research_supervisor":
                tracker['base_progress'] = 15.0
                stats = self._get_stats_summary(tracker)
                return {
                    'type': 'progress',
                    'stage': 'supervising',
                    'progress': 15.0,
                    'message': 'ğŸ¯ ç›‘ç£è€…ï¼šå¼€å§‹ç ”ç©¶ç¼–æ’',
                    'details': f'åˆ†æä»»åŠ¡ï¼Œåˆ¶å®šç ”ç©¶ç­–ç•¥\n{stats}',
                    'metadata': {'node': 'research_supervisor', 'event': 'start'}
                }
            
            # ç›‘ç£è€…å­å›¾èŠ‚ç‚¹
            elif event_name == "supervisor":
                tracker['supervisor_round'] += 1
                round_num = tracker['supervisor_round']
                # ç›‘ç£è€…æ¯è½®å ç”¨ä¸€å®šè¿›åº¦ï¼ˆ15%-75%åŒºé—´ï¼Œå…±60%ï¼‰
                progress = min(15.0 + (round_num - 1) * 10.0, 70.0)
                tracker['base_progress'] = progress
                
                stats = self._get_stats_summary(tracker)
                
                logger.info(f"[SUPERVISOR] ğŸ¯ ç¬¬{round_num}è½®è§„åˆ’å¼€å§‹ | {stats}")
                
                return {
                    'type': 'progress',
                    'stage': 'supervising',
                    'progress': progress,
                    'message': f'ğŸ¯ ç›‘ç£è€…ï¼šç¬¬{round_num}è½®è§„åˆ’',
                    'details': f'åˆ†æå½“å‰è¿›å±•ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨\n{stats}',
                    'metadata': {
                        'node': 'supervisor',
                        'event': 'start',
                        'round': round_num
                    }
                }
            
            elif event_name == "supervisor_tools":
                progress = tracker['base_progress'] + 2.0
                return {
                    'type': 'progress',
                    'stage': 'executing',
                    'progress': min(progress, 75.0),
                    'message': 'âš™ï¸ æ‰§è¡Œç›‘ç£è€…æŒ‡ä»¤',
                    'details': 'å¤„ç†å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œç ”ç©¶ä»»åŠ¡',
                    'metadata': {'node': 'supervisor_tools', 'event': 'start'}
                }
            
            # ç ”ç©¶è€…èŠ‚ç‚¹ï¼ˆä¸é‡å¤è®¡æ•°ï¼Œå·²åœ¨ConductResearchä¸­è®¡æ•°ï¼‰
            elif event_name == "researcher":
                count = tracker.get('researcher_count', 0)
                # ç ”ç©¶è€…åœ¨30%-60%åŒºé—´
                progress = 30.0 + min(count * 5.0, 30.0)
                
                # è®¡ç®—å·²ç”¨æ—¶é—´
                current_time = datetime.now().timestamp()
                elapsed_time = int(current_time - tracker.get('start_time', current_time))
                
                # ä¸å‘é€é‡å¤çš„ç ”ç©¶è€…å¯åŠ¨æ¶ˆæ¯ï¼ˆå·²åœ¨ConductResearchä¸­å‘é€ï¼‰
                # åªåœ¨researcherèŠ‚ç‚¹çœŸæ­£æ‰§è¡Œæ—¶å‘é€ä¸€æ¬¡æ±‡æ€»æ¶ˆæ¯
                return None
            
            elif event_name == "final_report_generation":
                tracker['base_progress'] = 75.0
                stats = self._get_stats_summary(tracker)
                return {
                    'type': 'progress',
                    'stage': 'generating_report',
                    'progress': 75.0,
                    'message': 'âœï¸ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š',
                    'details': f'æ•´åˆæ‰€æœ‰ç ”ç©¶å‘ç°ï¼Œæ’°å†™ç»¼åˆæŠ¥å‘Š\n{stats}',
                    'metadata': {'node': 'final_report_generation', 'event': 'start'}
                }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # èŠ‚ç‚¹å®Œæˆäº‹ä»¶
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        elif event_type == "on_chain_end":
            # ç›‘ç£è€…å®Œæˆï¼šæ˜¾ç¤ºå†³ç­–çš„å·¥å…·è°ƒç”¨
            if event_name == "supervisor":
                output = event.get("data", {}).get("output")
                
                # å®‰å…¨æå–æ•°æ®ï¼ˆå¤„ç† Command å¯¹è±¡ï¼‰
                supervisor_messages = []
                if output:
                    # å¤„ç† Command å¯¹è±¡
                    if hasattr(output, 'update') and isinstance(output.update, dict):
                        supervisor_messages = output.update.get("supervisor_messages", [])
                    # å¤„ç†æ™®é€šå­—å…¸
                    elif isinstance(output, dict):
                        supervisor_messages = output.get("supervisor_messages", [])
                
                # åˆ†æå·¥å…·è°ƒç”¨
                tool_calls_info = []
                if supervisor_messages:
                    # supervisor_messages å¯èƒ½æ˜¯å•ä¸ªæ¶ˆæ¯æˆ–æ¶ˆæ¯åˆ—è¡¨
                    msgs = supervisor_messages if isinstance(supervisor_messages, list) else [supervisor_messages]
                    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆAIçš„å“åº”ï¼‰
                    for msg in msgs:
                        if hasattr(msg, 'tool_calls') and msg.tool_calls:
                            for tc in msg.tool_calls:
                                tool_name = tc.get("name", "unknown") if isinstance(tc, dict) else getattr(tc, 'name', 'unknown')
                                tool_args = tc.get("args", {}) if isinstance(tc, dict) else getattr(tc, 'args', {})
                                tool_calls_info.append({
                                    'tool': tool_name,
                                    'args': tool_args
                                })
                
                # æ—¥å¿—ï¼šç›‘ç£è€…çš„å†³ç­–
                if tool_calls_info:
                    logger.info(f"[SUPERVISOR] âœ… å†³ç­–å®Œæˆï¼Œè®¡åˆ’è°ƒç”¨ {len(tool_calls_info)} ä¸ªå·¥å…·:")
                    for i, tc_info in enumerate(tool_calls_info, 1):
                        tool_display = tc_info['tool']
                        logger.info(f"  {i}. {tool_display}")
                        
                        # DEBUG æ¨¡å¼æ˜¾ç¤ºå®Œæ•´å‚æ•°
                        if logger.isEnabledFor(logging.DEBUG):
                            logger.debug(f"     å‚æ•°: {tc_info['args']}")
                        # INFO æ¨¡å¼æ˜¾ç¤ºå‚æ•°æ‘˜è¦
                        else:
                            if tc_info['tool'] == 'ConductResearch':
                                topic = str(tc_info['args'].get('research_topic', ''))[:80]
                                logger.info(f"     ä¸»é¢˜: {topic}...")
                            elif tc_info['tool'] == 'think_tool':
                                reflection = str(tc_info['args'].get('reflection', ''))[:80]
                                logger.info(f"     åæ€: {reflection}...")
                else:
                    logger.info(f"[SUPERVISOR] âœ… å†³ç­–å®Œæˆï¼Œæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ˆå¯èƒ½å·²ç»“æŸï¼‰")
                
                return None  # ä¸å•ç‹¬å‘é€è¿›åº¦ï¼Œé¿å…è¿‡å¤šè¾“å‡º
            
            elif event_name == "clarify_with_user":
                return {
                    'type': 'progress',
                    'stage': 'clarifying',
                    'progress': 5.0,
                    'message': 'âœ… é—®é¢˜æ¾„æ¸…å®Œæˆ',
                    'details': 'é—®é¢˜æ¸…æ™°ï¼Œç»§ç»­ç ”ç©¶',
                    'metadata': {'node': 'clarify_with_user', 'event': 'end'}
                }
            
            elif event_name == "write_research_brief":
                # æå–ç ”ç©¶ç®€æŠ¥å†…å®¹
                output = event.get("data", {}).get("output")
                
                # æ£€æŸ¥ output ç±»å‹ï¼ˆå¯èƒ½æ˜¯ Command å¯¹è±¡æˆ–å­—å…¸ï¼‰
                research_brief = ""
                if output and isinstance(output, dict):
                    research_brief = output.get("research_brief", "")
                elif output and hasattr(output, 'update'):
                    # Command å¯¹è±¡æœ‰ update å±æ€§
                    update_data = output.update if isinstance(output.update, dict) else {}
                    research_brief = update_data.get("research_brief", "")
                
                # DEBUG æ—¥å¿—ï¼šæ‰“å°å®Œæ•´çš„ç ”ç©¶ç®€æŠ¥
                if research_brief:
                    logger.info(f"[RESEARCH_BRIEF] ç ”ç©¶ç®€æŠ¥å·²ç”Ÿæˆï¼Œé•¿åº¦: {len(research_brief)} å­—ç¬¦")
                    if logger.isEnabledFor(logging.DEBUG):
                        logger.debug("=" * 60)
                        logger.debug("[ç ”ç©¶ç®€æŠ¥å®Œæ•´å†…å®¹]")
                        logger.debug("=" * 60)
                        logger.debug(research_brief)
                        logger.debug("=" * 60)
                    
                    # ç”Ÿæˆç®€æŠ¥æ‘˜è¦ï¼ˆå‰300å­—ç¬¦ï¼‰
                    brief_preview = research_brief[:300] + "..." if len(research_brief) > 300 else research_brief
                    
                    return {
                        'type': 'progress',
                        'stage': 'planning',
                        'progress': 15.0,
                        'message': 'âœ… ç ”ç©¶ç­–ç•¥è§„åˆ’å®Œæˆ',
                        'details': f'å·²ç”Ÿæˆç»“æ„åŒ–ç ”ç©¶ç®€æŠ¥\n\nç®€æŠ¥é¢„è§ˆ:\n{brief_preview}',
                        'research_brief': research_brief,
                        'metadata': {
                            'node': 'write_research_brief', 
                            'event': 'end',
                            'brief_length': len(research_brief)
                        }
                    }
                else:
                    # å¦‚æœæ²¡æœ‰æå–åˆ°ç®€æŠ¥ï¼Œè¿”å›åŸºæœ¬è¿›åº¦
                    return {
                        'type': 'progress',
                        'stage': 'planning',
                        'progress': 15.0,
                        'message': 'âœ… ç ”ç©¶ç­–ç•¥è§„åˆ’å®Œæˆ',
                        'details': 'å·²ç”Ÿæˆç»“æ„åŒ–ç ”ç©¶ç®€æŠ¥',
                        'metadata': {'node': 'write_research_brief', 'event': 'end'}
                    }
            
            elif event_name == "research_supervisor":
                # æå–ç ”ç©¶ç»“æœ
                output = event.get("data", {}).get("output")
                
                # å®‰å…¨æå–æ•°æ®ï¼ˆå¯èƒ½æ˜¯ dict æˆ– Command å¯¹è±¡ï¼‰
                notes = []
                if output and isinstance(output, dict):
                    notes = output.get("notes", [])
                
                if notes:
                    # DEBUG æ—¥å¿—ï¼šæ‰“å°ç ”ç©¶å‘ç°
                    logger.info(f"[RESEARCH_COMPLETE] ç ”ç©¶æ‰§è¡Œå®Œæˆï¼Œæ”¶é›†åˆ° {len(notes)} æ¡å…³é”®å‘ç°")
                    if logger.isEnabledFor(logging.DEBUG):
                        logger.debug("=" * 60)
                        logger.debug("[ç ”ç©¶å‘ç°åˆ—è¡¨]")
                        logger.debug("=" * 60)
                        for i, note in enumerate(notes[:10], 1):  # æœ€å¤šæ˜¾ç¤ºå‰10æ¡
                            logger.debug(f"{i}. {note}")
                        if len(notes) > 10:
                            logger.debug(f"... è¿˜æœ‰ {len(notes) - 10} æ¡å‘ç°")
                        logger.debug("=" * 60)
                    
                    # ç”Ÿæˆå‘ç°æ‘˜è¦
                    findings_preview = "\n".join([f"{i}. {note[:100]}..." for i, note in enumerate(notes[:3], 1)])
                    stats = self._get_stats_summary(tracker)
                    
                    return {
                        'type': 'progress',
                        'stage': 'supervising',
                        'progress': 75.0,
                        'message': 'âœ… ç ”ç©¶æ‰§è¡Œå®Œæˆ',
                        'details': f'æ”¶é›†åˆ° {len(notes)} æ¡å…³é”®å‘ç°\n{stats}\n\nå…³é”®å‘ç°é¢„è§ˆ:\n{findings_preview}',
                        'findings_count': len(notes),
                        'metadata': {
                            'node': 'research_supervisor', 
                            'event': 'end',
                            'notes_count': len(notes),
                            'total_searches': tracker.get('search_count', 0),
                            'total_researchers': tracker.get('researcher_count', 0)
                        }
                    }
                else:
                    # æ²¡æœ‰æå–åˆ°å‘ç°ï¼Œè¿”å›åŸºæœ¬è¿›åº¦
                    stats = self._get_stats_summary(tracker)
                    logger.info(f"[RESEARCH_COMPLETE] ç ”ç©¶æ‰§è¡Œå®Œæˆ | {stats}")
                    return {
                        'type': 'progress',
                        'stage': 'supervising',
                        'progress': 75.0,
                        'message': 'âœ… ç ”ç©¶æ‰§è¡Œå®Œæˆ',
                        'details': f'æ‰€æœ‰ç ”ç©¶ä»»åŠ¡å·²å®Œæˆ\n{stats}',
                        'metadata': {
                            'node': 'research_supervisor', 
                            'event': 'end',
                            'total_searches': tracker.get('search_count', 0),
                            'total_researchers': tracker.get('researcher_count', 0)
                        }
                    }
            
            elif event_name == "final_report_generation":
                stats = self._get_stats_summary(tracker)
                return {
                    'type': 'progress',
                    'stage': 'generating_report',
                    'progress': 95.0,
                    'message': 'âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ',
                    'details': f'æœ€ç»ˆç ”ç©¶æŠ¥å‘Šå·²ç”Ÿæˆ\n{stats}',
                    'metadata': {
                        'node': 'final_report_generation', 
                        'event': 'end',
                        'total_searches': tracker.get('search_count', 0),
                        'total_researchers': tracker.get('researcher_count', 0),
                        'total_rounds': tracker.get('supervisor_round', 0)
                    }
                }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # AIæ¨¡å‹è°ƒç”¨äº‹ä»¶ï¼ˆå¸¦å†·å´è¿‡æ»¤ï¼‰
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        elif event_type == "on_chat_model_start":
            current_node = tracker.get('current_node', 'unknown')
            current_time = datetime.now().timestamp()
            last_ai_time = tracker.get('last_ai_message_time', 0)
            cooldown = tracker.get('ai_message_cooldown', 2.0)
            
            # å†·å´æ—¶é—´å†…ï¼Œè·³è¿‡é‡å¤çš„AIæ¶ˆæ¯
            if current_time - last_ai_time < cooldown:
                return None
            
            # æ›´æ–°æœ€åå‘é€æ—¶é—´
            tracker['last_ai_message_time'] = current_time
            
            # è®¡ç®—å·²ç”¨æ—¶é—´
            elapsed_time = int(current_time - tracker.get('start_time', current_time))
            progress = tracker.get('base_progress', 0) + 1.0
            
            # ç”Ÿæˆç®€åŒ–çš„AIå¤„ç†æ¶ˆæ¯
            node_display = {
                'researcher': 'ç ”ç©¶å•å…ƒåˆ†æ',
                'supervisor': 'ç›‘ç£è€…å†³ç­–',
                'supervisor_planner': 'åˆ¶å®šç ”ç©¶è®¡åˆ’',
                'final_report_generation': 'ç”ŸæˆæŠ¥å‘Š',
                'clarify_with_user': 'é—®é¢˜åˆ†æ'
            }.get(current_node, 'å¤„ç†ä¸­')
            
            return {
                'type': 'progress',
                'stage': 'ai_processing',
                'progress': min(progress, 95.0),
                'message': f'ğŸ¤– AIåˆ†æï¼š{node_display}',
                'details': f'å·²è¿è¡Œ {elapsed_time}ç§’ | æœç´¢ {tracker.get("search_count", 0)}æ¬¡',
                'metadata': {
                    'model': event_name,
                    'node': current_node,
                    'event': 'ai_start',
                    'elapsed_seconds': elapsed_time,
                    'search_count': tracker.get('search_count', 0)
                }
            }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # å·¥å…·è°ƒç”¨äº‹ä»¶
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        elif event_type == "on_tool_start":
            tool_name = event_name
            tool_input = event.get("data", {}).get("input", {})
            progress = tracker.get('base_progress', 0) + 1.0
            
            # DEBUG æ—¥å¿—ï¼šè¯¦ç»†çš„å·¥å…·ä¿¡æ¯
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"[TOOL_START] Tool: {tool_name}")
                logger.debug(f"[TOOL_INPUT] {tool_input}")
            
            # æœç´¢å·¥å…·
            if "search" in tool_name.lower():
                # å¢åŠ æœç´¢è®¡æ•°
                tracker['search_count'] = tracker.get('search_count', 0) + 1
                search_num = tracker['search_count']
                
                query = tool_input.get("query", str(tool_input)[:100]) if isinstance(tool_input, dict) else str(tool_input)[:100]
                
                # è®¡ç®—å·²ç”¨æ—¶é—´
                current_time = datetime.now().timestamp()
                elapsed_time = int(current_time - tracker.get('start_time', current_time))
                
                logger.info(f"[TOOL] ğŸ” æœç´¢ #{search_num}: {query}")
                
                return {
                    'type': 'progress',
                    'stage': 'searching',
                    'progress': min(progress, 90.0),
                    'message': f'ğŸ” æœç´¢ #{search_num}',
                    'details': f'æŸ¥è¯¢: {query}\nå·²è¿è¡Œ {elapsed_time}ç§’',
                    'current_tool': tool_name,
                    'tool_input': query,
                    'metadata': {
                        'tool': tool_name,
                        'event': 'tool_start',
                        'search_number': search_num,
                        'elapsed_seconds': elapsed_time,
                        'total_searches': search_num,
                        'input': tool_input
                    }
                }
            
            # ç ”ç©¶å§”æ‰˜å·¥å…·
            elif tool_name == "ConductResearch":
                tracker['researcher_count'] = tracker.get('researcher_count', 0) + 1
                unit_num = tracker['researcher_count']
                
                topic = str(tool_input.get("research_topic", ""))[:100] if isinstance(tool_input, dict) else str(tool_input)[:100]
                
                # è®¡ç®—å·²ç”¨æ—¶é—´
                current_time = datetime.now().timestamp()
                elapsed_time = int(current_time - tracker.get('start_time', current_time))
                
                logger.info(f"[TOOL] ğŸš€ å¯åŠ¨ç ”ç©¶å•å…ƒ #{unit_num}: {topic}")
                
                return {
                    'type': 'progress',
                    'stage': 'delegating',
                    'progress': min(progress, 90.0),
                    'message': f'ğŸš€ å¯åŠ¨ç ”ç©¶å•å…ƒ #{unit_num}',
                    'details': f'ç ”ç©¶ä¸»é¢˜: {topic}\nå·²è¿è¡Œ {elapsed_time}ç§’ | å·²æœç´¢ {tracker.get("search_count", 0)}æ¬¡',
                    'current_tool': 'ConductResearch',
                    'tool_input': topic,
                    'metadata': {
                        'tool': 'ConductResearch',
                        'event': 'tool_start',
                        'unit_number': unit_num,
                        'elapsed_seconds': elapsed_time,
                        'total_searches': tracker.get('search_count', 0),
                        'topic': topic
                    }
                }
            
            # å…¶ä»–å·¥å…·ï¼ˆé€šç”¨å¤„ç†ï¼‰
            else:
                input_str = str(tool_input)[:100]
                
                logger.info(f"[TOOL] ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name} | è¾“å…¥: {input_str}")
                
                return {
                    'type': 'progress',
                    'stage': 'tool_calling',
                    'progress': min(progress, 90.0),
                    'message': f'ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}',
                    'details': f'è¾“å…¥: {input_str}',
                    'current_tool': tool_name,  # ğŸ‘ˆ æ–°å¢
                    'tool_input': input_str,    # ğŸ‘ˆ æ–°å¢
                    'metadata': {
                        'tool': tool_name,
                        'event': 'tool_start',
                        'input': tool_input
                    }
                }
        
        # å·¥å…·å®Œæˆäº‹ä»¶
        elif event_type == "on_tool_end":
            tool_name = event_name
            tool_output = event.get("data", {}).get("output", "")
            
            # DEBUG æ—¥å¿—ï¼šå·¥å…·è¾“å‡º
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"[TOOL_END] Tool: {tool_name}")
                logger.debug(f"[TOOL_OUTPUT] {str(tool_output)[:500]}")
            
            logger.info(f"[TOOL] âœ… å·¥å…·å®Œæˆ: {tool_name} | è¾“å‡ºé•¿åº¦: {len(str(tool_output))}")
        
        # å…¶ä»–äº‹ä»¶ä¸å¤„ç†ï¼Œé¿å…è¿‡å¤šè¾“å‡º
        return None

    def _convert_to_research_result(
        self,
        final_state: Dict[str, Any],
        start_time: datetime
    ) -> ResearchResult:
        """å°†æœ€ç»ˆçŠ¶æ€è½¬æ¢ä¸ºResearchResult"""
        duration = (datetime.now() - start_time).total_seconds()

        # æå–å…³é”®å‘ç°
        key_findings = []
        notes = final_state.get("notes", [])
        for note in notes:
            if len(note) > 10:
                key_findings.append(note)

        # æå–åŸå§‹ç¬”è®°
        raw_notes = final_state.get("raw_notes", [])

        # çŠ¶æ€æ˜ å°„
        status = "completed" if final_state.get("final_report") else "failed"

        # å®‰å…¨è·å–é—®é¢˜å†…å®¹
        messages = final_state.get("messages", [])
        question = ""
        if messages and len(messages) > 0:
            first_message = messages[0]
            if hasattr(first_message, 'content'):
                question = first_message.content
            elif isinstance(first_message, dict):
                question = first_message.get("content", "")

        return ResearchResult(
            question=question,
            final_report=final_state.get("final_report", ""),
            status=status,
            key_findings=key_findings[:20],  # é™åˆ¶æ•°é‡
            raw_notes=raw_notes[:50],  # é™åˆ¶æ•°é‡
            metadata={
                "duration": duration,
                "research_brief": final_state.get("research_brief", ""),
                "created_at": start_time.isoformat(),
                "completed_at": datetime.now().isoformat()
            }
        )

    async def get_research_status(self, research_id: str) -> Dict[str, Any]:
        """è·å–ç ”ç©¶çŠ¶æ€ï¼ˆæ‰©å±•åŠŸèƒ½ï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°çŠ¶æ€æŒä¹…åŒ–å’ŒæŸ¥è¯¢
        return {
            "research_id": research_id,
            "status": "not_implemented",
            "message": "çŠ¶æ€æŒä¹…åŒ–åŠŸèƒ½å¾…å®ç°"
        }

    async def cancel_research(self, research_id: str) -> bool:
        """å–æ¶ˆç ”ç©¶ï¼ˆæ‰©å±•åŠŸèƒ½ï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°ç ”ç©¶å–æ¶ˆåŠŸèƒ½
        logger.info(f"å–æ¶ˆç ”ç©¶è¯·æ±‚: {research_id}")
        return True

    def update_config(self, **kwargs):
        """æ›´æ–°é…ç½®"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
                logger.info(f"é…ç½®æ›´æ–°: {key} = {value}")
