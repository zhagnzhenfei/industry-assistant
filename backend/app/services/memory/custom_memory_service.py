"""
è‡ªå®šä¹‰è®°å¿†æœåŠ¡å®ç°
ä½¿ç”¨ PostgreSQL + Milvus + generate_embedding
å®Œå…¨è‡ªä¸»å®ç°ï¼Œä¸ä¾èµ– Mem0
"""
import logging
import json
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncpg
from pymilvus import connections, Collection, utility
import asyncio

from service.core.rag.nlp.model import generate_embedding

logger = logging.getLogger(__name__)


class CustomMemoryService:
    """
    è‡ªå®šä¹‰è®°å¿†æœåŠ¡
    
    æ¶æ„ï¼š
    - PostgreSQL: å­˜å‚¨è®°å¿†çš„å®Œæ•´æ•°æ®å’Œå…ƒæ•°æ®
    - Milvus: å­˜å‚¨å‘é‡ï¼Œç”¨äºè¯­ä¹‰æœç´¢
    - generate_embedding: ä½¿ç”¨é¡¹ç›®ä¸­çš„ DashScope API ç”Ÿæˆå‘é‡
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è‡ªå®šä¹‰è®°å¿†æœåŠ¡
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å« PostgreSQL å’Œ Milvus é…ç½®
        """
        self.config = config
        self.pg_pool: Optional[asyncpg.Pool] = None
        self.milvus_collection: Optional[Collection] = None
        self.collection_name = config.get("milvus_collection", "user_memories")
        self._initialized = False
        self._init_lock: Optional[asyncio.Lock] = None
    
    async def _ensure_initialized(self):
        """ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–"""
        if self._initialized:
            return
        
        if self._init_lock is None:
            self._init_lock = asyncio.Lock()
        
        async with self._init_lock:
            if self._initialized:
                return
            await self._initialize()
    
    async def _initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            # åˆå§‹åŒ– PostgreSQL è¿æ¥æ± 
            self.pg_pool = await asyncpg.create_pool(
                host=self.config["postgres_host"],
                port=self.config["postgres_port"],
                database=self.config["postgres_db"],
                user=self.config["postgres_user"],
                password=self.config["postgres_password"],
                min_size=1,
                max_size=10
            )
            
            # ç¡®ä¿è¡¨å­˜åœ¨
            await self._ensure_tables()
            
            # åˆå§‹åŒ– Milvus è¿æ¥
            connections.connect(
                alias="default",
                host=self.config["milvus_host"],
                port=str(self.config["milvus_port"])
            )
            
            # ç¡®ä¿ collection å­˜åœ¨
            await self._ensure_collection()
            
            self._initialized = True
            logger.info("âœ… è‡ªå®šä¹‰è®°å¿†æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ è‡ªå®šä¹‰è®°å¿†æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _ensure_tables(self):
        """ç¡®ä¿ PostgreSQL è¡¨å­˜åœ¨"""
        async with self.pg_pool.acquire() as conn:
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS memories (
                    id VARCHAR(36) PRIMARY KEY,
                    user_id VARCHAR(50) NOT NULL,
                    content TEXT NOT NULL,
                    metadata JSONB,
                    created_at TIMESTAMP DEFAULT NOW(),
                    updated_at TIMESTAMP DEFAULT NOW()
                );
                
                CREATE INDEX IF NOT EXISTS idx_memories_user_id ON memories(user_id);
                CREATE INDEX IF NOT EXISTS idx_memories_created_at ON memories(created_at DESC);
            """)
            logger.info("âœ… PostgreSQL è¡¨å·²å°±ç»ª")
    
    async def _ensure_collection(self):
        """ç¡®ä¿ Milvus collection å­˜åœ¨"""
        from pymilvus import CollectionSchema, FieldSchema, DataType
        
        if utility.has_collection(self.collection_name):
            logger.info(f"ğŸ“Š Collection '{self.collection_name}' å·²å­˜åœ¨")
            self.milvus_collection = Collection(self.collection_name)
            # æ£€æŸ¥ç°æœ‰collectionçš„å‘é‡ç»´åº¦æ˜¯å¦æ­£ç¡®
            schema = self.milvus_collection.schema
            vector_field = None
            for field in schema.fields:
                if field.name == "vector":
                    vector_field = field
                    break
            
            if vector_field and vector_field.params.get("dim") != 1024:
                logger.warning(f"âš ï¸ ç°æœ‰Collectionçš„å‘é‡ç»´åº¦æ˜¯ {vector_field.params.get('dim')}ï¼Œéœ€è¦1024ç»´")
                logger.warning("âš ï¸ å»ºè®®åˆ é™¤ç°æœ‰Collectionåé‡æ–°åˆ›å»ºï¼Œæˆ–ä½¿ç”¨åŒ¹é…çš„embeddingæ¨¡å‹")
        else:
            logger.info(f"ğŸ“Š åˆ›å»ºæ–° Collection: {self.collection_name}")
            
            # å®šä¹‰ schema
            # æ³¨æ„ï¼štext-embedding-v4 çš„ç»´åº¦æ˜¯ 1024
            fields = [
                FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, max_length=100),
                FieldSchema(name="user_id", dtype=DataType.VARCHAR, max_length=50),
                FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=1024),  # DashScope text-embedding-v4 ç»´åº¦æ˜¯ 1024
                FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=65535),
            ]
            
            schema = CollectionSchema(fields, "ç”¨æˆ·è®°å¿†å‘é‡é›†åˆ")
            self.milvus_collection = Collection(self.collection_name, schema)
            
            # åˆ›å»ºç´¢å¼•
            index_params = {
                "metric_type": "L2",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            }
            self.milvus_collection.create_index("vector", index_params)
        
        # åŠ è½½ collection
        self.milvus_collection.load()
        logger.info(f"âœ… Milvus Collection å·²å°±ç»ª")
    
    async def add_memory(
        self,
        user_id: str,
        content: str,
        metadata: Optional[Dict[str, Any]] = None,
        infer: bool = True
    ) -> Dict[str, Any]:
        """
        æ·»åŠ è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
            content: è®°å¿†å†…å®¹
            metadata: å…ƒæ•°æ®
            infer: æ˜¯å¦ä½¿ç”¨LLMæ™ºèƒ½æŠ½å–ï¼ˆæš‚æ—¶å¿½ç•¥ï¼Œåç»­å¯å®ç°ï¼‰
            
        Returns:
            æ·»åŠ ç»“æœ
        """
        await self._ensure_initialized()
        try:
            memory_id = str(uuid.uuid4())
            
            # ç”Ÿæˆå‘é‡
            logger.info(f"ç”Ÿæˆå‘é‡ - å†…å®¹é•¿åº¦: {len(content)}")
            embedding = generate_embedding(
                text=content,
                api_key=self.config.get("llm_api_key"),
                base_url=self.config.get("llm_base_url"),
                model_name=self.config.get("embedding_model", "text-embedding-v4")
            )
            
            # ä¿å­˜åˆ° PostgreSQL
            async with self.pg_pool.acquire() as conn:
                await conn.execute("""
                    INSERT INTO memories (id, user_id, content, metadata, created_at, updated_at)
                    VALUES ($1, $2, $3, $4, NOW(), NOW())
                """, memory_id, user_id, content, json.dumps(metadata or {}))
            
            # ä¿å­˜å‘é‡åˆ° Milvus
            # Milvus insert éœ€è¦æŒ‰ç…§å­—æ®µé¡ºåºæä¾›åˆ—è¡¨æ•°æ®
            # æ³¨æ„ï¼šæ¯ä¸ªå­—æ®µéƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå³ä½¿åªæœ‰ä¸€æ¡æ•°æ®
            self.milvus_collection.insert([
                [memory_id],           # id å­—æ®µ
                [user_id],             # user_id å­—æ®µ
                [embedding],           # vector å­—æ®µ
                [content[:65535]]      # content å­—æ®µï¼ˆé™åˆ¶é•¿åº¦ï¼‰
            ])
            
            logger.info(f"âœ… è®°å¿†æ·»åŠ æˆåŠŸ - ID: {memory_id}, ç”¨æˆ·: {user_id}")
            
            return {
                "success": True,
                "result": {
                    "id": memory_id,
                    "user_id": user_id,
                    "content": content[:200] + "..." if len(content) > 200 else content,
                    "metadata": metadata
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ è®°å¿†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def search_memories(
        self,
        user_id: str,
        query: str,
        limit: int = 10
    ) -> Dict[str, Any]:
        """
        æœç´¢è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢æ–‡æœ¬
            limit: è¿”å›æ•°é‡
            
        Returns:
            æœç´¢ç»“æœ
        """
        await self._ensure_initialized()
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = generate_embedding(
                text=query,
                api_key=self.config.get("llm_api_key"),
                base_url=self.config.get("llm_base_url"),
                model_name=self.config.get("embedding_model", "text-embedding-v4")
            )
            
            # åœ¨ Milvus ä¸­æœç´¢
            search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
            results = self.milvus_collection.search(
                data=[query_embedding],
                anns_field="vector",
                param=search_params,
                limit=limit,
                expr=f'user_id == "{user_id}"'  # è¿‡æ»¤ç”¨æˆ·
            )
            
            # è·å–åŒ¹é…çš„è®°å¿†ID
            memory_ids = []
            scores = []
            for hits in results:
                for hit in hits:
                    memory_ids.append(hit.id)
                    scores.append(hit.score)
            
            # ä» PostgreSQL è·å–å®Œæ•´æ•°æ®
            memories = []
            if memory_ids:
                async with self.pg_pool.acquire() as conn:
                    rows = await conn.fetch("""
                        SELECT id, content, metadata, created_at
                        FROM memories
                        WHERE id = ANY($1::text[])
                        ORDER BY created_at DESC
                    """, memory_ids)
                    
                    for i, row in enumerate(rows):
                        memories.append({
                            "id": row["id"],
                            "memory": {
                                "content": row["content"],
                                "metadata": json.loads(row["metadata"]) if row["metadata"] else {}
                            },
                            "metadata": json.loads(row["metadata"]) if row["metadata"] else {},
                            "score": float(scores[i]) if i < len(scores) else 0.0
                        })
            
            return {
                "success": True,
                "memories": memories,
                "total": len(memories)
            }
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢è®°å¿†å¤±è´¥: {e}")
            return {
                "success": False,
                "memories": [],
                "total": 0,
                "error": str(e)
            }
    
    async def get_all_memories(
        self,
        user_id: str,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·çš„æ‰€æœ‰è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›æ•°é‡
            
        Returns:
            è®°å¿†åˆ—è¡¨
        """
        await self._ensure_initialized()
        try:
            async with self.pg_pool.acquire() as conn:
                rows = await conn.fetch("""
                    SELECT id, content, metadata, created_at
                    FROM memories
                    WHERE user_id = $1
                    ORDER BY created_at DESC
                    LIMIT $2
                """, user_id, limit)
                
                memories = []
                for row in rows:
                    memories.append({
                        "id": row["id"],
                        "memory": {
                            "content": row["content"],
                            "metadata": json.loads(row["metadata"]) if row["metadata"] else {}
                        },
                        "metadata": json.loads(row["metadata"]) if row["metadata"] else {}
                    })
                
                return memories
                
        except Exception as e:
            logger.error(f"âŒ è·å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    async def get_context(
        self,
        user_id: str,
        query: str,
        limit: int = 5
    ) -> str:
        """
        è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆç”¨äºæç¤ºè¯å¢å¼ºï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢æ–‡æœ¬
            limit: è¿”å›æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        await self._ensure_initialized()
        try:
            result = await self.search_memories(user_id, query, limit)
            
            if not result.get("success") or not result.get("memories"):
                return ""
            
            context_parts = ["=== ç›¸å…³å†å²è®°å¿† ==="]
            for i, memory in enumerate(result["memories"], 1):
                content = memory.get("memory", {}).get("content", "")
                context_parts.append(f"{i}. {content[:200]}...")
            
            context_parts.append("=== è¯·åŸºäºä»¥ä¸Šå†å²è®°å¿†ï¼Œæä¾›æ›´ç›¸å…³çš„å›ç­” ===")
            
            return "\n".join(context_parts)
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return ""
    
    async def delete_memory(
        self,
        user_id: str,
        memory_id: str
    ) -> Dict[str, Any]:
        """
        åˆ é™¤è®°å¿†
        
        Args:
            user_id: ç”¨æˆ·ID
            memory_id: è®°å¿†ID
            
        Returns:
            åˆ é™¤ç»“æœ
        """
        await self._ensure_initialized()
        try:
            # ä» PostgreSQL åˆ é™¤
            async with self.pg_pool.acquire() as conn:
                result = await conn.execute("""
                    DELETE FROM memories
                    WHERE id = $1 AND user_id = $2
                """, memory_id, user_id)
            
            # ä» Milvus åˆ é™¤
            self.milvus_collection.delete(expr=f'id == "{memory_id}"')
            
            return {
                "success": True,
                "message": "è®°å¿†åˆ é™¤æˆåŠŸ"
            }
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤è®°å¿†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

