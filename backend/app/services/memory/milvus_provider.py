"""
Milvusè®°å¿†æä¾›è€… - MVPç‰ˆæœ¬

ä½¿ç”¨Milvusä½œä¸ºå•ä¸€å­˜å‚¨ï¼Œæ”¯æŒï¼š
1. çŸ­æœŸè®°å¿†ï¼ˆåŸºäºæ—¶é—´è¿‡æ»¤ï¼‰
2. é•¿æœŸè®°å¿†ï¼ˆå…¨é‡å­˜å‚¨ï¼‰
3. è¯­ä¹‰æ£€ç´¢ï¼ˆå‘é‡æœç´¢ï¼‰
4. ç®€å•ç”¨æˆ·ç”»åƒï¼ˆmetadataå­˜å‚¨ï¼‰
"""
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta

from .base import IMemoryProvider, ConversationMemory, UserProfile

logger = logging.getLogger(__name__)


class MilvusMemoryProvider(IMemoryProvider):
    """Milvusè®°å¿†æä¾›è€…
    
    Collectionè®¾è®¡:
    - conversation_id (VARCHAR, primary_key)
    - user_id (VARCHAR, æ”¯æŒè¿‡æ»¤)
    - vector (FLOAT_VECTOR, ç”¨äºè¯­ä¹‰æ£€ç´¢)
    - question (VARCHAR)
    - research_brief (VARCHAR)
    - final_report (VARCHAR)
    - key_findings (VARCHAR, JSON string)
    - quality_score (FLOAT)
    - duration (FLOAT)
    - created_at (VARCHAR, ISOæ ¼å¼)
    - metadata (VARCHAR, JSON string)
    """
    
    def __init__(
        self,
        milvus_host: str = "localhost",
        milvus_port: int = 19530,
        collection_name: str = "research_memory",
        embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2"
    ):
        self.host = milvus_host
        self.port = milvus_port
        self.collection_name = collection_name
        self.embedding_model_name = embedding_model_name
        
        self.client = None
        self.collection = None
        self.embedding_model = None
    
    async def initialize(self):
        """åˆå§‹åŒ–Milvusè¿æ¥å’Œcollection"""
        try:
            from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility
            
            # è¿æ¥Milvus
            logger.info(f"ğŸ”— è¿æ¥Milvus: {self.host}:{self.port}")
            connections.connect(
                alias="default",
                host=self.host,
                port=str(self.port)
            )
            logger.info("âœ… Milvusè¿æ¥æˆåŠŸ")
            
            # æ£€æŸ¥collectionæ˜¯å¦å­˜åœ¨
            if utility.has_collection(self.collection_name):
                logger.info(f"ğŸ“Š Collection '{self.collection_name}' å·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨")
                self.collection = Collection(self.collection_name)
            else:
                logger.info(f"ğŸ“Š åˆ›å»ºæ–°Collection: {self.collection_name}")
                self._create_collection()
            
            # åŠ è½½collectionåˆ°å†…å­˜
            self.collection.load()
            logger.info(f"âœ… Collectionå·²åŠ è½½åˆ°å†…å­˜")
            
            # åˆå§‹åŒ–embeddingæ¨¡å‹
            logger.info(f"ğŸ¤– åŠ è½½Embeddingæ¨¡å‹: {self.embedding_model_name}")
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer(self.embedding_model_name)
            logger.info("âœ… Embeddingæ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except ImportError as e:
            logger.error(f"âŒ ç¼ºå°‘å¿…è¦çš„åº“: {e}")
            logger.error("è¯·å®‰è£…: pip install pymilvus sentence-transformers")
            raise
        except Exception as e:
            logger.error(f"âŒ Milvusåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _create_collection(self):
        """åˆ›å»ºMilvus collection"""
        from pymilvus import Collection, CollectionSchema, FieldSchema, DataType
        
        # å®šä¹‰schema
        fields = [
            FieldSchema(name="conversation_id", dtype=DataType.VARCHAR, is_primary=True, max_length=100),
            FieldSchema(name="user_id", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=384),  # all-MiniLM-L6-v2çš„ç»´åº¦
            FieldSchema(name="question", dtype=DataType.VARCHAR, max_length=1000),
            FieldSchema(name="research_brief", dtype=DataType.VARCHAR, max_length=2000),
            FieldSchema(name="final_report", dtype=DataType.VARCHAR, max_length=10000),
            FieldSchema(name="key_findings", dtype=DataType.VARCHAR, max_length=5000),  # JSON string
            FieldSchema(name="quality_score", dtype=DataType.FLOAT),
            FieldSchema(name="duration", dtype=DataType.FLOAT),
            FieldSchema(name="created_at", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="metadata", dtype=DataType.VARCHAR, max_length=5000),  # JSON string
        ]
        
        schema = CollectionSchema(
            fields=fields,
            description="Research conversation memory storage"
        )
        
        # åˆ›å»ºcollection
        self.collection = Collection(
            name=self.collection_name,
            schema=schema
        )
        
        # åˆ›å»ºç´¢å¼•ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 128}
        }
        self.collection.create_index(
            field_name="vector",
            index_params=index_params
        )
        
        logger.info(f"âœ… Collection '{self.collection_name}' åˆ›å»ºæˆåŠŸ")
    
    async def load_memory(self, user_id: str) -> Dict[str, Any]:
        """åŠ è½½ç”¨æˆ·è®°å¿†ï¼ˆçŸ­æœŸ+é•¿æœŸï¼‰"""
        try:
            # å¹¶è¡Œè·å–çŸ­æœŸè®°å¿†å’Œç”¨æˆ·ç”»åƒ
            recent_conversations = await self.get_recent_conversations(user_id, limit=5)
            user_profile = await self.get_user_profile(user_id)
            
            return {
                "short_term_memory": [
                    {
                        "question": conv.question,
                        "research_brief": conv.research_brief,
                        "created_at": conv.created_at,
                        "quality_score": conv.quality_score
                    }
                    for conv in recent_conversations
                ],
                "user_profile": user_profile.__dict__ if user_profile else None
            }
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è®°å¿†å¤±è´¥: {e}")
            return {
                "short_term_memory": [],
                "user_profile": None
            }
    
    async def save_conversation(
        self, 
        user_id: str, 
        conversation: ConversationMemory
    ) -> None:
        """ä¿å­˜å¯¹è¯åˆ°Milvus"""
        try:
            # ç”Ÿæˆembedding
            text = f"{conversation.question} {conversation.research_brief}"
            embedding = self.embedding_model.encode(text).tolist()
            
            # å‡†å¤‡æ•°æ®
            entities = [
                [conversation.conversation_id],  # conversation_id
                [user_id],  # user_id
                [embedding],  # vector
                [conversation.question[:1000]],  # question (æˆªæ–­)
                [conversation.research_brief[:2000]],  # research_brief (æˆªæ–­)
                [conversation.final_report[:10000]],  # final_report (æˆªæ–­)
                [json.dumps(conversation.key_findings)[:5000]],  # key_findings (JSON)
                [conversation.quality_score],  # quality_score
                [conversation.duration],  # duration
                [conversation.created_at],  # created_at
                [json.dumps(conversation.metadata)[:5000]]  # metadata (JSON)
            ]
            
            # æ’å…¥Milvus
            self.collection.insert(entities)
            self.collection.flush()
            
            logger.info(f"âœ… å¯¹è¯å·²ä¿å­˜åˆ°Milvus: {conversation.conversation_id}")
            
            # æ›´æ–°ç”¨æˆ·ç”»åƒ
            await self.update_user_profile(user_id, conversation.__dict__)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¯¹è¯å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
    
    async def get_user_profile(self, user_id: str) -> Optional[UserProfile]:
        """ä»Milvusè·å–ç”¨æˆ·ç”»åƒ
        
        MVPå®ç°ï¼šåŸºäºå†å²å¯¹è¯ç»Ÿè®¡ç”Ÿæˆç®€å•ç”»åƒ
        """
        try:
            # æŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰å¯¹è¯
            expr = f'user_id == "{user_id}"'
            results = self.collection.query(
                expr=expr,
                output_fields=["question", "research_brief", "quality_score", "created_at", "key_findings"],
                limit=100
            )
            
            if not results:
                return None
            
            # ç»Ÿè®¡æ•°æ®
            total_researches = len(results)
            avg_quality = sum(r["quality_score"] for r in results) / total_researches if total_researches > 0 else 0
            
            # æå–ç ”ç©¶ä¸»é¢˜ï¼ˆç®€åŒ–ï¼šä»questionä¸­æå–å…³é”®è¯ï¼‰
            all_questions = " ".join(r["question"] for r in results)
            research_interests = self._extract_topics(all_questions)[:10]  # å–å‰10ä¸ªä¸»é¢˜
            
            # åˆ›å»ºç”¨æˆ·ç”»åƒ
            profile = UserProfile(
                user_id=user_id,
                expertise=[],  # MVPç‰ˆæœ¬æš‚æ—¶ä¸ºç©º
                research_interests=research_interests,
                preferred_depth="comprehensive",  # MVPç‰ˆæœ¬é»˜è®¤å€¼
                preferred_data_sources=["web"],  # MVPç‰ˆæœ¬é»˜è®¤å€¼
                statistics={
                    "total_researches": total_researches,
                    "avg_quality_score": avg_quality
                },
                created_at=results[0]["created_at"] if results else datetime.now().isoformat(),
                updated_at=datetime.now().isoformat()
            )
            
            return profile
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ç”»åƒå¤±è´¥: {e}")
            return None
    
    async def update_user_profile(
        self, 
        user_id: str, 
        research_data: Dict[str, Any]
    ) -> None:
        """æ›´æ–°ç”¨æˆ·ç”»åƒ
        
        MVPå®ç°ï¼šç”»åƒæ˜¯åŠ¨æ€ç”Ÿæˆçš„ï¼Œæ— éœ€æ˜¾å¼æ›´æ–°
        """
        # MVPç‰ˆæœ¬ï¼šç”»åƒåŸºäºå†å²æ•°æ®åŠ¨æ€ç”Ÿæˆï¼Œæ­¤æ–¹æ³•å¯ä¸ºç©º
        pass
    
    async def search_similar_conversations(
        self,
        user_id: str,
        query: str,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨Milvusè¿›è¡Œè¯­ä¹‰æœç´¢"""
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self.embedding_model.encode(query).tolist()
            
            # å‘é‡æœç´¢
            search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
            results = self.collection.search(
                data=[query_embedding],
                anns_field="vector",
                param=search_params,
                limit=limit,
                expr=f'user_id == "{user_id}"',
                output_fields=["conversation_id", "question", "research_brief", "created_at", "quality_score"]
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            similar = []
            for hits in results:
                for hit in hits:
                    similar.append({
                        "conversation_id": hit.entity.get("conversation_id"),
                        "question": hit.entity.get("question"),
                        "research_brief": hit.entity.get("research_brief"),
                        "score": hit.distance,
                        "created_at": hit.entity.get("created_at"),
                        "quality_score": hit.entity.get("quality_score")
                    })
            
            return similar
            
        except Exception as e:
            logger.error(f"âŒ è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            return []
    
    async def get_recent_conversations(
        self,
        user_id: str,
        limit: int = 5
    ) -> List[ConversationMemory]:
        """è·å–æœ€è¿‘çš„å¯¹è¯è®°å½•"""
        try:
            # æŸ¥è¯¢æœ€è¿‘Nå¤©çš„å¯¹è¯
            days_ago = (datetime.now() - timedelta(days=7)).isoformat()
            
            expr = f'user_id == "{user_id}"'
            results = self.collection.query(
                expr=expr,
                output_fields=[
                    "conversation_id", "question", "research_brief", 
                    "final_report", "key_findings", "quality_score", 
                    "duration", "created_at", "metadata"
                ],
                limit=limit
            )
            
            # è½¬æ¢ä¸ºConversationMemoryå¯¹è±¡
            conversations = []
            for r in results:
                conv = ConversationMemory(
                    conversation_id=r["conversation_id"],
                    user_id=user_id,
                    question=r["question"],
                    research_brief=r["research_brief"],
                    final_report=r.get("final_report", ""),
                    key_findings=json.loads(r.get("key_findings", "[]")),
                    quality_score=r.get("quality_score", 0.0),
                    duration=r.get("duration", 0.0),
                    created_at=r["created_at"],
                    metadata=json.loads(r.get("metadata", "{}"))
                )
                conversations.append(conv)
            
            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            conversations.sort(key=lambda x: x.created_at, reverse=True)
            
            return conversations[:limit]
            
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€è¿‘å¯¹è¯å¤±è´¥: {e}")
            return []
    
    def _extract_topics(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–ä¸»é¢˜ï¼ˆç®€åŒ–å®ç°ï¼‰
        
        MVPç‰ˆæœ¬ï¼šä½¿ç”¨ç®€å•çš„å…³é”®è¯æå–
        """
        # TODO: ä½¿ç”¨NLPæˆ–LLMæå–æ›´å‡†ç¡®çš„ä¸»é¢˜
        # ç®€åŒ–ç‰ˆæœ¬ï¼šåˆ†è¯+å»é‡+å–é«˜é¢‘è¯
        words = text.lower().split()
        word_counts = {}
        for word in words:
            if len(word) > 3:  # è¿‡æ»¤çŸ­è¯
                word_counts[word] = word_counts.get(word, 0) + 1
        
        # æŒ‰é¢‘ç‡æ’åº
        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words[:10]]

